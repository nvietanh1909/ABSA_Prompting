{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b265238",
   "metadata": {},
   "source": [
    "# Comparison Results: OpenAI GPT-4o vs Grok vs Gemini\n",
    "\n",
    "**Note về Grok API:**\n",
    "- Hiện tại Grok API chưa có tài liệu chính thức công khai\n",
    "- Code sử dụng URL giả định: `https://api.x.ai/v1/chat/completions`\n",
    "- Bạn cần có GROK_API_KEY hợp lệ trong file .env\n",
    "- Nếu API endpoint khác, hãy cập nhật URL trong function `call_grok_api()`\n",
    "\n",
    "**Mục đích:**\n",
    "So sánh hiệu suất của các mô hình LLM khác nhau với các kỹ thuật prompting khác nhau cho bài toán ABSA (Aspect-Based Sentiment Analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ca7e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Định nghĩa đường dẫn\n",
    "DATA_DIR = r\"c:\\Users\\Admin\\Python\\ABSA_Prompting\\data\"\n",
    "RESULT_DIR = r\"c:\\Users\\Admin\\Python\\ABSA_Prompting\\results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load và so sánh kết quả từ các mô hình và kỹ thuật\n",
    "results_comparison = []\n",
    "\n",
    "# Danh sách các kết quả cần so sánh\n",
    "experiments = [\n",
    "    # OpenAI GPT-4o\n",
    "    {\"model\": \"GPT-4o\", \"technique\": \"Zero-shot\", \"file\": \"ViABSA_BP_Zero-shot.json\"},\n",
    "    {\"model\": \"GPT-4o\", \"technique\": \"CoT\", \"file\": \"ViABSA_BP_CoT.json\"},\n",
    "    {\"model\": \"GPT-4o\", \"technique\": \"Few-shot-Clustering\", \"file\": \"ViABSA_BP_Few-shot-Clustering.json\"},\n",
    "    \n",
    "    # Grok\n",
    "    {\"model\": \"Grok\", \"technique\": \"Zero-shot\", \"file\": \"ViABSA_BP_Zero-shot_Grok.json\"},\n",
    "    {\"model\": \"Grok\", \"technique\": \"CoT\", \"file\": \"ViABSA_BP_CoT_Grok.json\"},\n",
    "    {\"model\": \"Grok\", \"technique\": \"Few-shot-Clustering\", \"file\": \"ViABSA_BP_Few-shot-Clustering_Grok.json\"},\n",
    "    \n",
    "    # Gemini\n",
    "    {\"model\": \"Gemini\", \"technique\": \"Zero-shot\", \"file\": \"ViABSA_BP_Zero-shot_Gemini.json\"},\n",
    "    {\"model\": \"Gemini\", \"technique\": \"CoT\", \"file\": \"ViABSA_BP_CoT_Gemini.json\"},\n",
    "    {\"model\": \"Gemini\", \"technique\": \"Few-shot-Clustering\", \"file\": \"ViABSA_BP_Few-shot-Clustering_Gemini.json\"},\n",
    "]\n",
    "\n",
    "# Load ground truth\n",
    "ViABSA_BP_dir = path.join(DATA_DIR, 'ViABSA_BP')\n",
    "test_file = path.join(ViABSA_BP_dir, 'data_test.csv')\n",
    "test_df = pd.read_csv(test_file)\n",
    "\n",
    "def transform_aspect_sentiment(df, start=0, end=None):\n",
    "    aspects = [\n",
    "        \"stayingpower\",\n",
    "        \"texture\",\n",
    "        \"smell\",\n",
    "        \"price\",\n",
    "        \"others\",\n",
    "        \"colour\",\n",
    "        \"shipping\",\n",
    "        \"packing\"\n",
    "    ]\n",
    "\n",
    "    if end is None:\n",
    "        end = len(df)\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for idx, row in df.iloc[start:end].iterrows():\n",
    "        entry = {\n",
    "            \"id\": str(idx),\n",
    "            \"text\": row['data'],\n",
    "            \"sentiments\": []\n",
    "        }\n",
    "\n",
    "        for aspect in aspects:\n",
    "            sentiment = row[f\"{aspect}_label\"]\n",
    "            if sentiment == 1:\n",
    "                aspect_sentiment_value = row[aspect]\n",
    "                if aspect_sentiment_value != 'none':\n",
    "                    entry[\"sentiments\"].append({\n",
    "                        \"aspect\": aspect,\n",
    "                        \"sentiment\": aspect_sentiment_value\n",
    "                    })\n",
    "                else:\n",
    "                    entry[\"sentiments\"].append({\n",
    "                        \"aspect\": aspect,\n",
    "                        \"sentiment\": \"unknown\"\n",
    "                    })\n",
    "\n",
    "        result.append(entry)\n",
    "\n",
    "    return result\n",
    "\n",
    "# Setup ground truth\n",
    "aspects = ['stayingpower', 'texture', 'smell', 'price', 'others', 'colour', 'shipping', 'packing']\n",
    "test_df[aspects] = test_df[aspects].fillna('none')\n",
    "\n",
    "for aspect in aspects:\n",
    "    test_df[aspect + '_label'] = (test_df[aspect] != 'none').astype(int)\n",
    "\n",
    "ground_truth = transform_aspect_sentiment(test_df, 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_aspect_sentiment(ground_truth, predictions):\n",
    "    true_aspects = []\n",
    "    pred_aspects = []\n",
    "\n",
    "    true_aspect_sentiments = []\n",
    "    pred_aspect_sentiments = []\n",
    "\n",
    "    for gt_entry, pred_entry in zip(ground_truth, predictions):\n",
    "        gt_sents = gt_entry['sentiments']\n",
    "        gt_aspect_set = set()\n",
    "        gt_aspect_sentiment_set = set()\n",
    "\n",
    "        for item in gt_sents:\n",
    "            gt_aspect_set.add(item['aspect'])\n",
    "            gt_aspect_sentiment_set.add((item['aspect'], item['sentiment']))\n",
    "\n",
    "        true_aspects.append(gt_aspect_set)\n",
    "        true_aspect_sentiments.append(gt_aspect_sentiment_set)\n",
    "\n",
    "        pred_sents = pred_entry['results']\n",
    "        pred_aspect_set = set()\n",
    "        pred_aspect_sentiment_set = set()\n",
    "\n",
    "        for item in pred_sents:\n",
    "            pred_aspect_set.add(item['aspect'])\n",
    "            pred_aspect_sentiment_set.add((item['aspect'], item['sentiment']))\n",
    "\n",
    "        pred_aspects.append(pred_aspect_set)\n",
    "        pred_aspect_sentiments.append(pred_aspect_sentiment_set)\n",
    "\n",
    "    tp_aspect = sum(len(gt & pred) for gt, pred in zip(true_aspects, pred_aspects))\n",
    "    fp_aspect = sum(len(pred - gt) for gt, pred in zip(true_aspects, pred_aspects))\n",
    "    fn_aspect = sum(len(gt - pred) for gt, pred in zip(true_aspects, pred_aspects))\n",
    "\n",
    "    precision_aspect = tp_aspect / (tp_aspect + fp_aspect + 1e-8)\n",
    "    recall_aspect = tp_aspect / (tp_aspect + fn_aspect + 1e-8)\n",
    "    f1_aspect = 2 * precision_aspect * recall_aspect / (precision_aspect + recall_aspect + 1e-8)\n",
    "\n",
    "    tp_sentiment = sum(len(gt & pred) for gt, pred in zip(true_aspect_sentiments, pred_aspect_sentiments))\n",
    "    fp_sentiment = sum(len(pred - gt) for gt, pred in zip(true_aspect_sentiments, pred_aspect_sentiments))\n",
    "    fn_sentiment = sum(len(gt - pred) for gt, pred in zip(true_aspect_sentiments, pred_aspect_sentiments))\n",
    "\n",
    "    precision_sentiment = tp_sentiment / (tp_sentiment + fp_sentiment + 1e-8)\n",
    "    recall_sentiment = tp_sentiment / (tp_sentiment + fn_sentiment + 1e-8)\n",
    "    f1_sentiment = 2 * precision_sentiment * recall_sentiment / (precision_sentiment + recall_sentiment + 1e-8)\n",
    "\n",
    "    return {\n",
    "        \"Aspect Detection F1\": f1_aspect,\n",
    "        \"Sentiment Classification F1\": f1_sentiment\n",
    "    }\n",
    "\n",
    "# Đánh giá từng experiment\n",
    "for exp in experiments:\n",
    "    result_file = path.join(RESULT_DIR, exp[\"file\"])\n",
    "    \n",
    "    if os.path.exists(result_file):\n",
    "        with open(result_file, 'r', encoding='utf-8') as f:\n",
    "            predictions = json.load(f)\n",
    "        \n",
    "        scores = evaluate_aspect_sentiment(ground_truth, predictions)\n",
    "        \n",
    "        results_comparison.append({\n",
    "            \"Model\": exp[\"model\"],\n",
    "            \"Technique\": exp[\"technique\"],\n",
    "            \"Aspect Detection F1\": scores[\"Aspect Detection F1\"],\n",
    "            \"Sentiment Classification F1\": scores[\"Sentiment Classification F1\"],\n",
    "            \"File\": exp[\"file\"]\n",
    "        })\n",
    "    else:\n",
    "        print(f\"File not found: {result_file}\")\n",
    "\n",
    "# Tạo DataFrame kết quả\n",
    "results_df = pd.DataFrame(results_comparison)\n",
    "print(\"=== COMPARISON RESULTS ===\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabc98bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo biểu đồ so sánh\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Aspect Detection F1\n",
    "pivot_aspect = results_df.pivot(index='Technique', columns='Model', values='Aspect Detection F1')\n",
    "pivot_aspect.plot(kind='bar', ax=axes[0], title='Aspect Detection F1 Score Comparison')\n",
    "axes[0].set_ylabel('F1 Score')\n",
    "axes[0].legend(title='Model')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Sentiment Classification F1\n",
    "pivot_sentiment = results_df.pivot(index='Technique', columns='Model', values='Sentiment Classification F1')\n",
    "pivot_sentiment.plot(kind='bar', ax=axes[1], title='Sentiment Classification F1 Score Comparison')\n",
    "axes[1].set_ylabel('F1 Score')\n",
    "axes[1].legend(title='Model')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2066222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo heatmap so sánh\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Heatmap cho Aspect Detection\n",
    "sns.heatmap(pivot_aspect, annot=True, fmt='.4f', cmap='YlOrRd', ax=axes[0])\n",
    "axes[0].set_title('Aspect Detection F1 Score Heatmap')\n",
    "\n",
    "# Heatmap cho Sentiment Classification\n",
    "sns.heatmap(pivot_sentiment, annot=True, fmt='.4f', cmap='YlOrRd', ax=axes[1])\n",
    "axes[1].set_title('Sentiment Classification F1 Score Heatmap')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0047318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tóm tắt kết quả theo từng model\n",
    "print(\"\\n=== SUMMARY BY MODEL ===\")\n",
    "summary_by_model = results_df.groupby('Model').agg({\n",
    "    'Aspect Detection F1': ['mean', 'std', 'max'],\n",
    "    'Sentiment Classification F1': ['mean', 'std', 'max']\n",
    "}).round(4)\n",
    "print(summary_by_model)\n",
    "\n",
    "print(\"\\n=== SUMMARY BY TECHNIQUE ===\")\n",
    "summary_by_technique = results_df.groupby('Technique').agg({\n",
    "    'Aspect Detection F1': ['mean', 'std', 'max'],\n",
    "    'Sentiment Classification F1': ['mean', 'std', 'max']\n",
    "}).round(4)\n",
    "print(summary_by_technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb34a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tìm best performance\n",
    "print(\"\\n=== BEST PERFORMANCE ===\")\n",
    "best_aspect = results_df.loc[results_df['Aspect Detection F1'].idxmax()]\n",
    "best_sentiment = results_df.loc[results_df['Sentiment Classification F1'].idxmax()]\n",
    "\n",
    "print(\"Best Aspect Detection:\")\n",
    "print(f\"Model: {best_aspect['Model']}, Technique: {best_aspect['Technique']}, F1: {best_aspect['Aspect Detection F1']:.4f}\")\n",
    "\n",
    "print(\"\\nBest Sentiment Classification:\")\n",
    "print(f\"Model: {best_sentiment['Model']}, Technique: {best_sentiment['Technique']}, F1: {best_sentiment['Sentiment Classification F1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25da4245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save kết quả so sánh\n",
    "results_df.to_csv(path.join(RESULT_DIR, 'comparison_results.csv'), index=False)\n",
    "print(f\"\\nResults saved to: {path.join(RESULT_DIR, 'comparison_results.csv')}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
