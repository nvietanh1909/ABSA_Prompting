{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e00688a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Python\\ABSA_Prompting\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\Python\\ABSA_Prompting\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "\n",
    "# Định nghĩa đường dẫn\n",
    "DATA_DIR = r\"c:\\Users\\Admin\\Python\\ABSA_Prompting\\data\"\n",
    "RESULT_DIR = r\"c:\\Users\\Admin\\Python\\ABSA_Prompting\\results\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4a836f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fa5c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "ViABSA_BP_dir = path.join(DATA_DIR, 'ViABSA_Hotel')\n",
    "test_file = path.join(ViABSA_BP_dir, 'data_test.csv')\n",
    "test_df = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c4defe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects = [\n",
    "    \"FACILITIES#CLEANLINESS\",\n",
    "    \"FACILITIES#COMFORT\",\n",
    "    \"FACILITIES#DESIGN&FEATURES\",\n",
    "    \"FACILITIES#GENERAL\",\n",
    "    \"FACILITIES#MISCELLANEOUS\",\n",
    "    \"FACILITIES#PRICES\",\n",
    "    \"FACILITIES#QUALITY\",\n",
    "    \"FOOD&DRINKS#MISCELLANEOUS\",\n",
    "    \"FOOD&DRINKS#PRICES\",\n",
    "    \"FOOD&DRINKS#QUALITY\",\n",
    "    \"FOOD&DRINKS#STYLE&OPTIONS\",\n",
    "    \"HOTEL#CLEANLINESS\",\n",
    "    \"HOTEL#COMFORT\",\n",
    "    \"HOTEL#DESIGN&FEATURES\",\n",
    "    \"HOTEL#GENERAL\",\n",
    "    \"HOTEL#MISCELLANEOUS\",\n",
    "    \"HOTEL#PRICES\",\n",
    "    \"HOTEL#QUALITY\",\n",
    "    \"LOCATION#GENERAL\",\n",
    "    \"ROOMS#CLEANLINESS\",\n",
    "    \"ROOMS#COMFORT\",\n",
    "    \"ROOMS#DESIGN&FEATURES\",\n",
    "    \"ROOMS#GENERAL\",\n",
    "    \"ROOMS#MISCELLANEOUS\",\n",
    "    \"ROOMS#PRICES\",\n",
    "    \"ROOMS#QUALITY\",\n",
    "    \"ROOM_AMENITIES#CLEANLINESS\",\n",
    "    \"ROOM_AMENITIES#COMFORT\",\n",
    "    \"ROOM_AMENITIES#DESIGN&FEATURES\",\n",
    "    \"ROOM_AMENITIES#GENERAL\",\n",
    "    \"ROOM_AMENITIES#MISCELLANEOUS\",\n",
    "    \"ROOM_AMENITIES#PRICES\",\n",
    "    \"ROOM_AMENITIES#QUALITY\",\n",
    "    \"SERVICE#GENERAL\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e858e993",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = {\n",
    "    1: \"positive\",\n",
    "    2: \"negative\",\n",
    "    3: \"neutral\"\n",
    "}\n",
    "\n",
    "def transform_aspect_sentiment(df, start=0, end=None):\n",
    "    result = [] \n",
    "    \n",
    "    if end is None:\n",
    "        end = len(df)\n",
    "\n",
    "    for idx, row in df.iloc[start:end].iterrows():\n",
    "        entry = {\n",
    "            \"id\": str(idx),\n",
    "            \"text\": row['Review'],\n",
    "            \"sentiments\": []\n",
    "        }\n",
    "\n",
    "        for aspect in aspects:\n",
    "            sentiment = row[f\"{aspect}_label\"]\n",
    "            if sentiment == 1:  # chỉ lấy những cái có sentiment\n",
    "                aspect_sentiment_value = row[aspect]\n",
    "                mapped_sent = sentiment_map.get(aspect_sentiment_value, \"unknown\")\n",
    "                if aspect_sentiment_value != 'none':\n",
    "                    entry[\"sentiments\"].append({\n",
    "                        \"aspect\": aspect,\n",
    "                        \"sentiment\": mapped_sent\n",
    "                    })\n",
    "                else:\n",
    "                    # nếu cột sentiment text bị none nhưng label == 1 thì có thể log ra kiểm tra\n",
    "                    entry[\"sentiments\"].append({\n",
    "                        \"aspect\": aspect,\n",
    "                        \"sentiment\": \"unknown\"\n",
    "                    })\n",
    "\n",
    "        result.append(entry)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce6741f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '0',\n",
       "  'text': 'Ga giường không sạch, nhân viên quên dọn phòng một ngày.',\n",
       "  'sentiments': [{'aspect': 'ROOM_AMENITIES#CLEANLINESS',\n",
       "    'sentiment': 'negative'},\n",
       "   {'aspect': 'SERVICE#GENERAL', 'sentiment': 'negative'}]},\n",
       " {'id': '1',\n",
       "  'text': 'Nv nhiệt tình, phòng ở sạch sẽ, tiện nghi, vị trí khá thuận tiện cho việc di chuyển đến các địa điểm ăn + chơi Phòng có gián',\n",
       "  'sentiments': [{'aspect': 'LOCATION#GENERAL', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOMS#CLEANLINESS', 'sentiment': 'neutral'},\n",
       "   {'aspect': 'ROOMS#COMFORT', 'sentiment': 'positive'},\n",
       "   {'aspect': 'SERVICE#GENERAL', 'sentiment': 'positive'}]},\n",
       " {'id': '2',\n",
       "  'text': 'Đi bộ ra biển gần, tiện đi lại Phòng view biển nhưng cửa sổ view biển khá bé',\n",
       "  'sentiments': [{'aspect': 'LOCATION#GENERAL', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOMS#DESIGN&FEATURES', 'sentiment': 'neutral'},\n",
       "   {'aspect': 'ROOMS#GENERAL', 'sentiment': 'positive'}]},\n",
       " {'id': '3',\n",
       "  'text': 'Tất cả mọi thứ đều sạch sẽ, giường ngủ rất thoải mái. Không có quạt điện mà chỉ có điều hòa nên có chút bất tiện.',\n",
       "  'sentiments': [{'aspect': 'HOTEL#CLEANLINESS', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOM_AMENITIES#COMFORT', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOM_AMENITIES#DESIGN&FEATURES', 'sentiment': 'negative'}]},\n",
       " {'id': '4',\n",
       "  'text': 'Giường sạch sẽ, thoải mái, đầy đủ thiết bị cần thiết, ăn cũng trang bị sẵn nếu bạn lười Phòng tắm chưa chia được ko gian khô và ướt',\n",
       "  'sentiments': [{'aspect': 'FOOD&DRINKS#STYLE&OPTIONS',\n",
       "    'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOM_AMENITIES#CLEANLINESS', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOM_AMENITIES#COMFORT', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOM_AMENITIES#DESIGN&FEATURES', 'sentiment': 'negative'},\n",
       "   {'aspect': 'ROOM_AMENITIES#GENERAL', 'sentiment': 'positive'}]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SETUP DATA\n",
    "test_df[aspects] = test_df[aspects].fillna('none')\n",
    "\n",
    "for aspect in aspects:\n",
    "    test_df[aspect + '_label'] = (test_df[aspect] != 0).astype(int)\n",
    "\n",
    "test_json = transform_aspect_sentiment(test_df, 0, 100)\n",
    "test_json[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41d81c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 19/19 [00:05<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 3 diverse examples:\n",
      "\n",
      "Example 545:\n",
      "bữa sáng ngon,nhân viên vui vẻ,tận tình,đặc biết cô bé Ly rất chu đáo và tận tình. đồ ăn sáng hơi it món,phòng tắm quá nhỏ\n",
      "\n",
      "Example 302:\n",
      "Phòng sạch sẽ, thoải mái. Nhân viên vui vẻ thái độ phục vục nhiệt tình, thân thiện.\n",
      "\n",
      "Example 358:\n",
      "Tiện nghi đầy đủ thoải mái, nhân viên nhiệt tình và rất thân thiện. Tuy không phải khách sạn tốt nhất nhưng thái độ phục vụ làm mình rất ấn tượng và để lại dấu ấn tốt ở đây. Nhược điểm hơi ít phòng và tầng, hơn nữa khách sạn nằm trong con đường mới xây nên di chuyển hay gọi xe hầu như đều phải ra trục đường chính. View không đẹp lắm\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Nếu dùng TD-IDF thì sẽ chỉ chọn dựa vào tần suất từ, không hiểu nghĩa của câu -> bị trùng lặp\n",
    "    Semantic grouping để chọn example đa dạng về nội dung, không chỉ về các từ\n",
    "'''\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(test_df['Review'].tolist(), show_progress_bar=True)\n",
    "\n",
    "# KMeans clustering (70% đa dạng, 30% khó)\n",
    "n_total = 5\n",
    "n_diverse = int(n_total * 0.7)\n",
    "n_hard = n_total - n_diverse\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_diverse, random_state=42, n_init=10)\n",
    "kmeans.fit(embeddings)\n",
    "\n",
    "# Lấy diverse example gần cluster centroid\n",
    "closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, embeddings)\n",
    "diverse_examples = test_df.iloc[closest]\n",
    "\n",
    "print(f\"Selected {len(diverse_examples)} diverse examples:\")\n",
    "for i, row in diverse_examples.iterrows():\n",
    "    print(f\"\\nExample {i}:\\n{row['Review']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "770ce84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 19/19 [00:04<00:00,  4.61it/s]\n"
     ]
    }
   ],
   "source": [
    "def select_few_shot_examples(df, text_column, n_total=5, model_name='all-MiniLM-L6-v2', random_state=42):\n",
    "    n_diverse = int(n_total * 0.7)\n",
    "    n_hard = n_total - n_diverse\n",
    "\n",
    "    model = SentenceTransformer(model_name)\n",
    "    embeddings = model.encode(df[text_column].tolist(), show_progress_bar=True)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_diverse, random_state=random_state, n_init=10)\n",
    "    kmeans.fit(embeddings)\n",
    "\n",
    "    closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, embeddings)\n",
    "    diverse_df = df.iloc[closest]\n",
    "\n",
    "    all_indices = np.arange(len(df))\n",
    "    remaining_indices = list(set(all_indices) - set(closest))\n",
    "    hard_df = df.iloc[remaining_indices].sample(n=n_hard, random_state=random_state)\n",
    "\n",
    "    return diverse_df.reset_index(drop=True), hard_df.reset_index(drop=True)\n",
    "\n",
    "# SET-UP FEW-SHOT EXAMPLES\n",
    "diverse, hard = select_few_shot_examples(test_df, text_column='Review', n_total=10)\n",
    "\n",
    "few_shot_json =  transform_aspect_sentiment(diverse, 0, 100) + transform_aspect_sentiment(hard, 0, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a824d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '0',\n",
       "  'text': 'Nhân viên thân thiện, nhiệt tình Nhà tắm nhỏ, tiện nghi chưa ngăn nắp, phòng ốc bí.',\n",
       "  'sentiments': [{'aspect': 'ROOMS#COMFORT', 'sentiment': 'negative'},\n",
       "   {'aspect': 'ROOM_AMENITIES#DESIGN&FEATURES', 'sentiment': 'negative'},\n",
       "   {'aspect': 'SERVICE#GENERAL', 'sentiment': 'positive'}]},\n",
       " {'id': '1',\n",
       "  'text': 'Phòng sạch sẽ, đang khuyến mại nên giá rẻ. Sáng sớm và tối rất ầm ĩ, vì Khách sạn và nhà bên cạnh đang xây dựng, chính vì vậy nên giá phòng đang giảm giá. Lễ tân đứng tuổi lịch sự nhiệt tình. Lễ tân trẻ tuổi ban đầu không cho khách đặt đồ gửi trong phòng gửi đồ, lý do là sợ nhầm lẫn với đồ của khách khác trong phòng, lý do hết sức vô lý, phải đến khi khách ko đồng ý để ngoài góc sảnh vì có máy ảnh lễ tân mới mở phòng gửi đồ. Vị trí xa, xung quanh ít cửa hàng dịch vụ, bù lại xe máy có thể thuê ngay tại khách sạn',\n",
       "  'sentiments': [{'aspect': 'FACILITIES#DESIGN&FEATURES',\n",
       "    'sentiment': 'positive'},\n",
       "   {'aspect': 'HOTEL#COMFORT', 'sentiment': 'negative'},\n",
       "   {'aspect': 'HOTEL#MISCELLANEOUS', 'sentiment': 'negative'},\n",
       "   {'aspect': 'LOCATION#GENERAL', 'sentiment': 'negative'},\n",
       "   {'aspect': 'ROOMS#CLEANLINESS', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOMS#PRICES', 'sentiment': 'positive'},\n",
       "   {'aspect': 'SERVICE#GENERAL', 'sentiment': 'neutral'}]},\n",
       " {'id': '2',\n",
       "  'text': 'Phòng sạch sẽ, đầy đủ tiện nghi. Quá hợp lý với mức giá phòng. Gần biển, thuận tiện đi tới các địa điểm. Nhân viên khách sạn nhiệt tình, dễ mến. Wifi hơi yếu, cần khuyếch tán wifi và cách âm chưa được tốt lắm. Tuy nhiên điều đó không quá ảnh hưởng, nếu được khắc phục sẽ hoàn hảo hơn !',\n",
       "  'sentiments': [{'aspect': 'FACILITIES#QUALITY', 'sentiment': 'negative'},\n",
       "   {'aspect': 'HOTEL#GENERAL', 'sentiment': 'positive'},\n",
       "   {'aspect': 'LOCATION#GENERAL', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOMS#CLEANLINESS', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOMS#DESIGN&FEATURES', 'sentiment': 'negative'},\n",
       "   {'aspect': 'ROOMS#PRICES', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOM_AMENITIES#GENERAL', 'sentiment': 'positive'},\n",
       "   {'aspect': 'SERVICE#GENERAL', 'sentiment': 'positive'}]},\n",
       " {'id': '3',\n",
       "  'text': 'Vị trí tốt, ngay cầu rồng và cầu sông hàn , buổi tối ra đường ngắm cảnh đẹp,gần chợ hàn thuận tiện ăn uống.nhân viên thân thiện và nhiệt tình Bữa ăn sáng ko được ngon miệng,ít món,khách sạn hơi xuống cấp so với lần nghỉ trước, mền rách và không được sạch, nước nóng lúc được lúc không.',\n",
       "  'sentiments': [{'aspect': 'FOOD&DRINKS#QUALITY', 'sentiment': 'negative'},\n",
       "   {'aspect': 'FOOD&DRINKS#STYLE&OPTIONS', 'sentiment': 'negative'},\n",
       "   {'aspect': 'HOTEL#QUALITY', 'sentiment': 'negative'},\n",
       "   {'aspect': 'LOCATION#GENERAL', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOM_AMENITIES#CLEANLINESS', 'sentiment': 'negative'},\n",
       "   {'aspect': 'ROOM_AMENITIES#DESIGN&FEATURES', 'sentiment': 'negative'},\n",
       "   {'aspect': 'ROOM_AMENITIES#QUALITY', 'sentiment': 'negative'},\n",
       "   {'aspect': 'SERVICE#GENERAL', 'sentiment': 'positive'}]},\n",
       " {'id': '4',\n",
       "  'text': 'Phòng sạch sẽ, thoải mái. Nhân viên vui vẻ thái độ phục vục nhiệt tình, thân thiện.',\n",
       "  'sentiments': [{'aspect': 'ROOMS#CLEANLINESS', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOMS#COMFORT', 'sentiment': 'positive'},\n",
       "   {'aspect': 'SERVICE#GENERAL', 'sentiment': 'positive'}]},\n",
       " {'id': '5',\n",
       "  'text': 'Bữa sáng ngon nhưng khá ít lựa chọn, khách sạn đẹp, phòng gọn gàng, dọn phòng mỗi ngày, nhân viên thân thiện',\n",
       "  'sentiments': [{'aspect': 'FOOD&DRINKS#QUALITY', 'sentiment': 'positive'},\n",
       "   {'aspect': 'FOOD&DRINKS#STYLE&OPTIONS', 'sentiment': 'negative'},\n",
       "   {'aspect': 'HOTEL#DESIGN&FEATURES', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOMS#CLEANLINESS', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOMS#DESIGN&FEATURES', 'sentiment': 'positive'},\n",
       "   {'aspect': 'SERVICE#GENERAL', 'sentiment': 'positive'}]},\n",
       " {'id': '6',\n",
       "  'text': 'Phòng đẹp và sạch sẽ, nhân viên phục vụ rất nhiệt tình, hồ bơi và minibar trên sân thượng rất đẹp nhưng sau 22h không được ngắm cảnh nữa, hơi tiếc. Đánh giá chung: rất tốt, sẽ quay lại vào những lần sau :)',\n",
       "  'sentiments': [{'aspect': 'FACILITIES#DESIGN&FEATURES',\n",
       "    'sentiment': 'positive'},\n",
       "   {'aspect': 'FACILITIES#MISCELLANEOUS', 'sentiment': 'negative'},\n",
       "   {'aspect': 'HOTEL#GENERAL', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOMS#CLEANLINESS', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOMS#DESIGN&FEATURES', 'sentiment': 'positive'},\n",
       "   {'aspect': 'SERVICE#GENERAL', 'sentiment': 'positive'}]},\n",
       " {'id': '0',\n",
       "  'text': 'Từ khách sạn ra tới biển không quá xa. Phục vụ khách sạn rất tốt. Các quán ăn rất gần và ngon Đi tắm không nên mang theo dép vì có thể bị mất',\n",
       "  'sentiments': [{'aspect': 'FACILITIES#MISCELLANEOUS',\n",
       "    'sentiment': 'negative'},\n",
       "   {'aspect': 'HOTEL#MISCELLANEOUS', 'sentiment': 'negative'},\n",
       "   {'aspect': 'LOCATION#GENERAL', 'sentiment': 'positive'},\n",
       "   {'aspect': 'SERVICE#GENERAL', 'sentiment': 'positive'}]},\n",
       " {'id': '1',\n",
       "  'text': 'Giường rất thoải mái, phòng ốc tiện nghi',\n",
       "  'sentiments': [{'aspect': 'ROOMS#COMFORT', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOM_AMENITIES#COMFORT', 'sentiment': 'positive'}]},\n",
       " {'id': '2',\n",
       "  'text': 'Nhân viên rất nhiệt tình, dễ thương🙂 Trong phòng ngủ, trên giường có bụi, mền và gối có mùi .... , phòng cách âm hơi tệ, rất ồn',\n",
       "  'sentiments': [{'aspect': 'ROOMS#CLEANLINESS', 'sentiment': 'negative'},\n",
       "   {'aspect': 'ROOMS#COMFORT', 'sentiment': 'negative'},\n",
       "   {'aspect': 'ROOMS#DESIGN&FEATURES', 'sentiment': 'negative'},\n",
       "   {'aspect': 'ROOM_AMENITIES#CLEANLINESS', 'sentiment': 'negative'},\n",
       "   {'aspect': 'SERVICE#GENERAL', 'sentiment': 'positive'}]}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_json[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c3958de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_aspect_sentiment(ground_truth, predictions):\n",
    "    # Chuẩn hóa dữ liệu thành list các tuple để so sánh\n",
    "    true_aspects = []\n",
    "    pred_aspects = []\n",
    "\n",
    "    true_aspect_sentiments = []\n",
    "    pred_aspect_sentiments = []\n",
    "\n",
    "    for gt_entry, pred_entry in zip(ground_truth, predictions):\n",
    "        # ground truth: list of sentiments\n",
    "        gt_sents = gt_entry['sentiments']\n",
    "        gt_aspect_set = set()\n",
    "        gt_aspect_sentiment_set = set()\n",
    "\n",
    "        for item in gt_sents:\n",
    "            gt_aspect_set.add(item['aspect'])\n",
    "            gt_aspect_sentiment_set.add((item['aspect'], item['sentiment']))\n",
    "\n",
    "        true_aspects.append(gt_aspect_set)\n",
    "        true_aspect_sentiments.append(gt_aspect_sentiment_set)\n",
    "\n",
    "        # prediction: list of results\n",
    "        pred_sents = pred_entry['results']\n",
    "        pred_aspect_set = set()\n",
    "        pred_aspect_sentiment_set = set()\n",
    "\n",
    "        for item in pred_sents:\n",
    "            pred_aspect_set.add(item['aspect'])\n",
    "            pred_aspect_sentiment_set.add((item['aspect'], item['sentiment']))\n",
    "\n",
    "        pred_aspects.append(pred_aspect_set)\n",
    "        pred_aspect_sentiments.append(pred_aspect_sentiment_set)\n",
    "\n",
    "    # Tính theo micro-F1 (gộp hết lại)\n",
    "    all_true_aspects = set.union(*true_aspects) if true_aspects else set()\n",
    "    all_pred_aspects = set.union(*pred_aspects) if pred_aspects else set()\n",
    "\n",
    "    tp_aspect = sum(len(gt & pred) for gt, pred in zip(true_aspects, pred_aspects))\n",
    "    fp_aspect = sum(len(pred - gt) for gt, pred in zip(true_aspects, pred_aspects))\n",
    "    fn_aspect = sum(len(gt - pred) for gt, pred in zip(true_aspects, pred_aspects))\n",
    "\n",
    "    precision_aspect = tp_aspect / (tp_aspect + fp_aspect + 1e-8)\n",
    "    recall_aspect = tp_aspect / (tp_aspect + fn_aspect + 1e-8)\n",
    "    f1_aspect = 2 * precision_aspect * recall_aspect / (precision_aspect + recall_aspect + 1e-8)\n",
    "\n",
    "    # Tính cho sentiment classification\n",
    "    tp_sentiment = sum(len(gt & pred) for gt, pred in zip(true_aspect_sentiments, pred_aspect_sentiments))\n",
    "    fp_sentiment = sum(len(pred - gt) for gt, pred in zip(true_aspect_sentiments, pred_aspect_sentiments))\n",
    "    fn_sentiment = sum(len(gt - pred) for gt, pred in zip(true_aspect_sentiments, pred_aspect_sentiments))\n",
    "\n",
    "    precision_sentiment = tp_sentiment / (tp_sentiment + fp_sentiment + 1e-8)\n",
    "    recall_sentiment = tp_sentiment / (tp_sentiment + fn_sentiment + 1e-8)\n",
    "    f1_sentiment = 2 * precision_sentiment * recall_sentiment / (precision_sentiment + recall_sentiment + 1e-8)\n",
    "\n",
    "    return {\n",
    "        \"Aspect Detection F1\": f1_aspect,\n",
    "        \"Sentiment Classification F1\": f1_sentiment\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "59cf8edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:05<00:00,  2.45s/it]\n"
     ]
    }
   ],
   "source": [
    "# Setup Grok API\n",
    "def call_grok_api(prompt):\n",
    "    url = \"https://api.x.ai/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {os.getenv('GROK_API_KEY')}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": \"grok-3\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts aspects and their sentiments from text.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=data, timeout=30)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result['choices'][0]['message']['content']\n",
    "        else:\n",
    "            print(f\"API Error: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Request Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_clustering_prompt(text, few_shot_examples):\n",
    "    prompt = \"You are an AI assistant that extracts aspects and their sentiments from text.\\n\\n\"\n",
    "    \n",
    "    # Thêm few-shot examples\n",
    "    for ex in few_shot_examples:\n",
    "        prompt += f\"Extract aspects and sentiments from the following review:\\n{ex['text']}\\n\"\n",
    "        prompt += f\"Result: {json.dumps({'results': ex['sentiments']}, ensure_ascii=False)}\\n\\n\"\n",
    "    \n",
    "    # Thêm câu hỏi hiện tại\n",
    "    prompt += f\"Extract aspects and sentiments from the following review:\\n{text}\\n\"\n",
    "    prompt += f\"Available aspects: {', '.join(aspects)}\\n\"\n",
    "    prompt += \"Available sentiments: positive, negative, neutral\\n\"\n",
    "    prompt += \"Return ONLY a valid JSON object in this exact format:\\n\"\n",
    "    prompt += '{\"results\": [{\"aspect\": \"aspect_name\", \"sentiment\": \"sentiment_value\"}]}'\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def extract_with_grok_clustering(text, few_shot_examples):\n",
    "    prompt = create_clustering_prompt(text, few_shot_examples)\n",
    "    response_text = call_grok_api(prompt)\n",
    "    \n",
    "    if response_text:\n",
    "        try:\n",
    "            # Tìm JSON trong response\n",
    "            start_idx = response_text.find('{')\n",
    "            end_idx = response_text.rfind('}') + 1\n",
    "            \n",
    "            if start_idx != -1 and end_idx != -1:\n",
    "                json_str = response_text[start_idx:end_idx]\n",
    "                parsed_output = json.loads(json_str)\n",
    "                return parsed_output\n",
    "            else:\n",
    "                return {\"results\": []}\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"JSON Parse Error: {response_text}\")\n",
    "            return {\"results\": []}\n",
    "    else:\n",
    "        return {\"results\": []}\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# Dự đoán\n",
    "for data in tqdm(test_json):\n",
    "    prediction = extract_with_grok_clustering(data['text'], few_shot_json)\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "722d5306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Aspect Detection F1': 0.7214285664238946, 'Sentiment Classification F1': 0.6571428521397108}\n"
     ]
    }
   ],
   "source": [
    "scores = evaluate_aspect_sentiment(test_json, predictions)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "11a75653",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = path.join(RESULT_DIR, 'ViABSA_BP_Few-Hotel-Grok.json')\n",
    "with open(result_file, 'w') as f:\n",
    "    json.dump(predictions, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d64b3e0",
   "metadata": {},
   "source": [
    "k = 1 với ví dụ gần tâm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "016c0d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:22<05:11,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Parse Error: {\" there! I'm happy to help with extracting aspects and sentiments from the provided review. Based on the text \"Rộng rãi, sạch sẽ. Có chỗ trong phòng không bắt được wifi\" and the available aspects and sentiments, here's the result in the requested JSON format:\n",
      "\n",
      "{\"results\": [{\"aspect\": \"ROOMS#COMFORT\", \"sentiment\": \"positive\"}, {\"aspect\": \"ROOMS#CLEANLINESS\", \"sentiment\": \"positive\"}, {\"aspect\": \"ROOM_AMENITIES#QUALITY\", \"sentiment\": \"negative\"}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:57<00:00,  3.57s/it]\n"
     ]
    }
   ],
   "source": [
    "# Setup Grok API\n",
    "def call_grok_api(prompt):\n",
    "    url = \"https://api.x.ai/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {os.getenv('GROK_API_KEY')}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": \"grok-3\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts aspects and their sentiments from text.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=data, timeout=30)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result['choices'][0]['message']['content']\n",
    "        else:\n",
    "            print(f\"API Error: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Request Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_clustering_prompt(text, few_shot_examples):\n",
    "    prompt = \"You are an AI assistant that extracts aspects and their sentiments from text.\\n\\n\"\n",
    "    \n",
    "    # Thêm few-shot examples\n",
    "    for ex in few_shot_examples:\n",
    "        prompt += f\"Extract aspects and sentiments from the following review:\\n{ex['text']}\\n\"\n",
    "        prompt += f\"Result: {json.dumps({'results': ex['sentiments']}, ensure_ascii=False)}\\n\\n\"\n",
    "    \n",
    "    # Thêm câu hỏi hiện tại\n",
    "    prompt += f\"Extract aspects and sentiments from the following review:\\n{text}\\n\"\n",
    "    prompt += f\"Available aspects: {', '.join(aspects)}\\n\"\n",
    "    prompt += \"Available sentiments: positive, negative, neutral\\n\"\n",
    "    prompt += \"Return ONLY a valid JSON object in this exact format:\\n\"\n",
    "    prompt += '{\"results\": [{\"aspect\": \"aspect_name\", \"sentiment\": \"sentiment_value\"}]}'\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def extract_with_grok_clustering(text, few_shot_examples):\n",
    "    prompt = create_clustering_prompt(text, few_shot_examples)\n",
    "    response_text = call_grok_api(prompt)\n",
    "    \n",
    "    if response_text:\n",
    "        try:\n",
    "            # Tìm JSON trong response\n",
    "            start_idx = response_text.find('{')\n",
    "            end_idx = response_text.rfind('}') + 1\n",
    "            \n",
    "            if start_idx != -1 and end_idx != -1:\n",
    "                json_str = response_text[start_idx:end_idx]\n",
    "                parsed_output = json.loads(json_str)\n",
    "                return parsed_output\n",
    "            else:\n",
    "                return {\"results\": []}\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"JSON Parse Error: {response_text}\")\n",
    "            return {\"results\": []}\n",
    "    else:\n",
    "        return {\"results\": []}\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# Dự đoán\n",
    "for data in tqdm(test_json):\n",
    "    prediction = extract_with_grok_clustering(data['text'], few_shot_json)\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f1a01ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Aspect Detection F1': 0.709219853148316, 'Sentiment Classification F1': 0.6359338011405922}\n"
     ]
    }
   ],
   "source": [
    "scores = evaluate_aspect_sentiment(test_json, predictions)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08df29da",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = path.join(RESULT_DIR, 'ViABSA_BP_Few-Hotel-Grok-N1-c.json')\n",
    "with open(result_file, 'w') as f:\n",
    "    json.dump(predictions, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e32251",
   "metadata": {},
   "source": [
    "k = 1 với ví dụ xa tâm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0b7c9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [03:11<01:55,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Parse Error: {\" {\"results\": [\n",
      "    {\"aspect\": \"LOCATION#GENERAL\", \"sentiment\": \"positive\"},\n",
      "    {\"aspect\": \"SERVICE#GENERAL\", \"sentiment\": \"positive\"},\n",
      "    {\"aspect\": \"FOOD&DRINKS#QUALITY\", \"sentiment\": \"negative\"},\n",
      "    {\"aspect\": \"FOOD&DRINKS#STYLE&OPTIONS\", \"sentiment\": \"negative\"},\n",
      "    {\"aspect\": \"HOTEL#QUALITY\", \"sentiment\": \"negative\"},\n",
      "    {\"aspect\": \"ROOM_AMENITIES#CLEANLINESS\", \"sentiment\": \"negative\"},\n",
      "    {\"aspect\": \"ROOM_AMENITIES#QUALITY\", \"sentiment\": \"negative\"}\n",
      "  ]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:03<00:00,  3.64s/it]\n"
     ]
    }
   ],
   "source": [
    "# Setup Grok API\n",
    "def call_grok_api(prompt):\n",
    "    url = \"https://api.x.ai/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {os.getenv('GROK_API_KEY')}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": \"grok-3\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts aspects and their sentiments from text.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=data, timeout=30)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result['choices'][0]['message']['content']\n",
    "        else:\n",
    "            print(f\"API Error: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Request Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_clustering_prompt(text, few_shot_examples):\n",
    "    prompt = \"You are an AI assistant that extracts aspects and their sentiments from text.\\n\\n\"\n",
    "    \n",
    "    # Thêm few-shot examples\n",
    "    for ex in few_shot_examples:\n",
    "        prompt += f\"Extract aspects and sentiments from the following review:\\n{ex['text']}\\n\"\n",
    "        prompt += f\"Result: {json.dumps({'results': ex['sentiments']}, ensure_ascii=False)}\\n\\n\"\n",
    "    \n",
    "    # Thêm câu hỏi hiện tại\n",
    "    prompt += f\"Extract aspects and sentiments from the following review:\\n{text}\\n\"\n",
    "    prompt += f\"Available aspects: {', '.join(aspects)}\\n\"\n",
    "    prompt += \"Available sentiments: positive, negative, neutral\\n\"\n",
    "    prompt += \"Return ONLY a valid JSON object in this exact format:\\n\"\n",
    "    prompt += '{\"results\": [{\"aspect\": \"aspect_name\", \"sentiment\": \"sentiment_value\"}]}'\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def extract_with_grok_clustering(text, few_shot_examples):\n",
    "    prompt = create_clustering_prompt(text, few_shot_examples)\n",
    "    response_text = call_grok_api(prompt)\n",
    "    \n",
    "    if response_text:\n",
    "        try:\n",
    "            # Tìm JSON trong response\n",
    "            start_idx = response_text.find('{')\n",
    "            end_idx = response_text.rfind('}') + 1\n",
    "            \n",
    "            if start_idx != -1 and end_idx != -1:\n",
    "                json_str = response_text[start_idx:end_idx]\n",
    "                parsed_output = json.loads(json_str)\n",
    "                return parsed_output\n",
    "            else:\n",
    "                return {\"results\": []}\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"JSON Parse Error: {response_text}\")\n",
    "            return {\"results\": []}\n",
    "    else:\n",
    "        return {\"results\": []}\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# Dự đoán\n",
    "for data in tqdm(test_json):\n",
    "    prediction = extract_with_grok_clustering(data['text'], few_shot_json)\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21d91e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Aspect Detection F1': 0.7570754666882956, 'Sentiment Classification F1': 0.6910377308407963}\n"
     ]
    }
   ],
   "source": [
    "scores = evaluate_aspect_sentiment(test_json, predictions)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822458f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = path.join(RESULT_DIR, 'ViABSA_BP_Few-Hotel-Grok-N1-f.json')\n",
    "with open(result_file, 'w') as f:\n",
    "    json.dump(predictions, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c9234a",
   "metadata": {},
   "source": [
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccaa8dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [05:01<00:13,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Parse Error: {\" there! I'm happy to help with extracting aspects and sentiments from the provided review. Here's the result in the exact JSON format you requested:\n",
      "\n",
      "{\"results\": [{\"aspect\": \"ROOMS#COMFORT\", \"sentiment\": \"positive\"}, {\"aspect\": \"ROOM_AMENITIES#GENERAL\", \"sentiment\": \"positive\"}, {\"aspect\": \"FOOD&DRINKS#STYLE&OPTIONS\", \"sentiment\": \"negative\"}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:17<00:00,  3.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# Setup Grok API\n",
    "def call_grok_api(prompt):\n",
    "    url = \"https://api.x.ai/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {os.getenv('GROK_API_KEY')}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": \"grok-3\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts aspects and their sentiments from text.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=data, timeout=30)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result['choices'][0]['message']['content']\n",
    "        else:\n",
    "            print(f\"API Error: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Request Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_clustering_prompt(text, few_shot_examples):\n",
    "    prompt = \"You are an AI assistant that extracts aspects and their sentiments from text.\\n\\n\"\n",
    "    \n",
    "    # Thêm few-shot examples\n",
    "    for ex in few_shot_examples:\n",
    "        prompt += f\"Extract aspects and sentiments from the following review:\\n{ex['text']}\\n\"\n",
    "        prompt += f\"Result: {json.dumps({'results': ex['sentiments']}, ensure_ascii=False)}\\n\\n\"\n",
    "    \n",
    "    # Thêm câu hỏi hiện tại\n",
    "    prompt += f\"Extract aspects and sentiments from the following review:\\n{text}\\n\"\n",
    "    prompt += f\"Available aspects: {', '.join(aspects)}\\n\"\n",
    "    prompt += \"Available sentiments: positive, negative, neutral\\n\"\n",
    "    prompt += \"Return ONLY a valid JSON object in this exact format:\\n\"\n",
    "    prompt += '{\"results\": [{\"aspect\": \"aspect_name\", \"sentiment\": \"sentiment_value\"}]}'\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def extract_with_grok_clustering(text, few_shot_examples):\n",
    "    prompt = create_clustering_prompt(text, few_shot_examples)\n",
    "    response_text = call_grok_api(prompt)\n",
    "    \n",
    "    if response_text:\n",
    "        try:\n",
    "            # Tìm JSON trong response\n",
    "            start_idx = response_text.find('{')\n",
    "            end_idx = response_text.rfind('}') + 1\n",
    "            \n",
    "            if start_idx != -1 and end_idx != -1:\n",
    "                json_str = response_text[start_idx:end_idx]\n",
    "                parsed_output = json.loads(json_str)\n",
    "                return parsed_output\n",
    "            else:\n",
    "                return {\"results\": []}\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"JSON Parse Error: {response_text}\")\n",
    "            return {\"results\": []}\n",
    "    else:\n",
    "        return {\"results\": []}\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# Dự đoán\n",
    "for data in tqdm(test_json):\n",
    "    prediction = extract_with_grok_clustering(data['text'], few_shot_json)\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aae634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Aspect Detection F1': 0.8624613505235967, 'Sentiment Classification F1': 0.7211177119997286}\n"
     ]
    }
   ],
   "source": [
    "scores = evaluate_aspect_sentiment(test_json, predictions)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3041d4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = path.join(RESULT_DIR, 'ViABSA_BP_Few-Hotel-Grok-N10.json')\n",
    "with open(result_file, 'w') as f:\n",
    "    json.dump(predictions, f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ABSA_Prompting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
