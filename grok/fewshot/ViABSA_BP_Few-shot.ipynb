{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b8cf38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n\n",
    "DATA_DIR = r\"c:\\Users\\Admin\\Python\\ABSA_Prompting\\data\"\n",
    "RESULT_DIR = r\"c:\\Users\\Admin\\Python\\ABSA_Prompting\\results\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcf4f3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5505c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "ViABSA_BP_dir = path.join(DATA_DIR, 'ViABSA_BP')\n",
    "test_file = path.join(ViABSA_BP_dir, 'data_test.csv')\n",
    "test_df = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c06aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_aspect_sentiment(df, start=0, end=None):\n",
    "    aspects = [\n",
    "        \"stayingpower\",\n",
    "        \"texture\",\n",
    "        \"smell\",\n",
    "        \"price\",\n",
    "        \"others\",\n",
    "        \"colour\",\n",
    "        \"shipping\",\n",
    "        \"packing\"\n",
    "    ]\n",
    "\n",
    "    if end is None:\n",
    "        end = len(df)\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for idx, row in df.iloc[start:end].iterrows():\n",
    "        entry = {\n",
    "            \"id\": str(idx),\n",
    "            \"text\": row['data'],\n",
    "            \"sentiments\": []\n",
    "        }\n",
    "\n",
    "        for aspect in aspects:\n",
    "            sentiment = row[f\"{aspect}_label\"]\n",
    "            if sentiment == 1: \n",
    "                aspect_sentiment_value = row[aspect]\n",
    "                if aspect_sentiment_value != 'none':\n",
    "                    entry[\"sentiments\"].append({\n",
    "                        \"aspect\": aspect,\n",
    "                        \"sentiment\": aspect_sentiment_value\n",
    "                    })\n",
    "                else:\n",
    "                    entry[\"sentiments\"].append({\n",
    "                        \"aspect\": aspect,\n",
    "                        \"sentiment\": \"unknown\"\n",
    "                    })\n",
    "\n",
    "        result.append(entry)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24c9bdc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '0',\n",
       "  'text': 'H√†ng ƒë√≥ng g√≥i ƒë·∫πp v√† ch·∫Øc ch·∫Øn, nh√¨n r·∫•t d·ªÖ th∆∞∆°ng v√† ∆∞ng b·ª•ng ·∫°!',\n",
       "  'sentiments': [{'aspect': 'packing', 'sentiment': 'positive'}]},\n",
       " {'id': '1',\n",
       "  'text': 'C·∫£m gi√°c son b√™n trong r·∫•t l√† √≠t lu√¥n √≠, ƒë√≥ng g√≥i c·∫©n th·∫≠n, d·ªãch nh∆∞ng m√† giao h√†ng kh√° nhanh',\n",
       "  'sentiments': [{'aspect': 'shipping', 'sentiment': 'positive'},\n",
       "   {'aspect': 'packing', 'sentiment': 'positive'}]},\n",
       " {'id': '2',\n",
       "  'text': 'Son si√™u ƒë·∫πp lu√¥n √Ω, m√† y h√¨nh m√† ch·ª•p c√≥ th·ªÉ kh√¥ng gi·ªëng l·∫Øm nh∆∞ng nh√¨n ngo√†i th√¨ gi·ªëng nha. Ch·∫•t son m·ªÅm m∆∞·ªõt n√≥i chung l√† r·∫•t th√≠chhhh',\n",
       "  'sentiments': [{'aspect': 'texture', 'sentiment': 'positive'}]},\n",
       " {'id': '3',\n",
       "  'text': 'Siu ƒë·∫πp lu√¥n \\r\\nShop ƒë√≥ng g√≥i c·∫©n th·∫≠n l·∫Øm lu√¥n \\r\\nL·∫°i th√™m c·∫£ qu√† n·ªØa\\r\\nN√≥i chung l√† th√≠ch l·∫Øm',\n",
       "  'sentiments': [{'aspect': 'packing', 'sentiment': 'positive'}]},\n",
       " {'id': '4',\n",
       "  'text': 'A√∫hihƒëcyihb gfxxth jj bhgfzƒëE G GHVHBTCEETXUBBIYCZRZRTCVUUBYRZXGVBIINVUTXZRCTIBONONBUXTZRTVKNNOUVTXEecyuvknibtcrztxuvbubibijvcytdgunonobiyvdtrdfyyghuojpmibvytcdtvunomobuCYYVBIBIYCTXYVIONNIXTXTBUOJMOONBIYCXRTXVYBUINNONIBUCTTXTCYVIBONON',\n",
       "  'sentiments': [{'aspect': 'others', 'sentiment': 'neutral'}]}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SETUP DATA\n",
    "aspects = ['stayingpower', 'texture', 'smell', 'price', 'others', 'colour', 'shipping', 'packing']\n",
    "test_df[aspects] = test_df[aspects].fillna('none')\n",
    "\n",
    "for aspect in aspects:\n",
    "    test_df[aspect + '_label'] = (test_df[aspect] != 'none').astype(int)\n",
    "\n",
    "test_json = transform_aspect_sentiment(test_df, 0, 100)\n",
    "test_json[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2833b59a",
   "metadata": {},
   "source": [
    "**√ù t∆∞·ªüng ch·ªçn example cho few-shot**\n",
    "1.   Ch·ªçn ra nh·ªØng c√¢u ƒëa d·∫°ng v·ªÅ aspect t·ª´ dataset -> g√¥m c·ª•m ch√∫ng l·∫°i ƒë·ªÉ LLMs hi·ªÉu r√µ h∆°n v·ªÅ pattern ƒë·ªÉ h·ªçc\n",
    "2.   Ch·ªçn ra nh·ªØng c√¢u kh√≥, nh·ªØng c√¢u ph·ª©c t·∫°p h∆°n \n",
    "\n",
    "√Åp d·ª•ng K-Means Clustering + Ch·ªçn Centroid + Sampling Example kh√≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b791059d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51/51 [00:12<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 3 diverse examples:\n",
      "\n",
      "Example 1524:\n",
      "Son ƒë·∫πp, h√†ng h·ªãnüòÅ, m√™ l·∫Øm lu√¥n, tuy k l·ª≥ nh∆∞ng b√π l·∫°i b√¥i l√™n m√¥i n√≥ kh√¥ng b·ªã kh√¥ m√¥i, xinh l·∫Øm lu√¥n, ƒë√≥ng g√≥i r·∫•t ch·∫Øc ch·∫Øn, gi√° r·∫ª, giao h√†ng t·ª´ TQ v·ªÅ VN n√™n h∆°i l√¢u...nh∆∞ng kh√¥ng saoüòäxinh l√† th√≠chüòÇüòÇ n√™n mua ·ªßng h·ªô shop nh√© m.n\n",
      "\n",
      "Example 1574:\n",
      "M√†u son ƒë·∫πp nh∆∞ng h∆°i l√¢u kh√¥ t√≠... \n",
      "Ch·∫•t son c≈©ng t·∫°m ƒë∆∞·ª£c\n",
      "V·ªè son ƒë·∫πp\n",
      "Son th∆°m c·ª±c luoonnnn\n",
      "\n",
      "Example 1591:\n",
      "ƒë·∫πppppppppppp xƒ©uuuuuuuuuuuu hdjhsjsjsjdjdjjdjdjdjdjd\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    N·∫øu d√πng TD-IDF th√¨ s·∫Ω ch·ªâ ch·ªçn d·ª±a v√†o t·∫ßn su·∫•t t·ª´, kh√¥ng hi·ªÉu nghƒ©a c·ªßa c√¢u -> b·ªã tr√πng l·∫∑p\n",
    "    Semantic grouping ƒë·ªÉ ch·ªçn example ƒëa d·∫°ng v·ªÅ n·ªôi dung, kh√¥ng ch·ªâ v·ªÅ c√°c t·ª´\n",
    "'''\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(test_df['data'].tolist(), show_progress_bar=True)\n",
    "\n",
    "# KMeans clustering (70% ƒëa d·∫°ng, 30% kh√≥)\n",
    "n_total = 5\n",
    "n_diverse = int(n_total * 0.7)\n",
    "n_hard = n_total - n_diverse\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_diverse, random_state=42, n_init=10)\n",
    "kmeans.fit(embeddings)\n",
    "\n",
    "# L·∫•y diverse example g·∫ßn cluster centroid\n",
    "closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, embeddings)\n",
    "diverse_examples = test_df.iloc[closest]\n",
    "\n",
    "print(f\"Selected {len(diverse_examples)} diverse examples:\")\n",
    "for i, row in diverse_examples.iterrows():\n",
    "    print(f\"\\nExample {i}:\\n{row['data']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96064b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2 hard examples:\n",
      "\n",
      "Example 135:\n",
      "son s·ªãn . m√†u ƒë·∫πp jaisidiisisjsjsjsjdiididdiidjsjdjjdididi\n",
      "\n",
      "Example 479:\n",
      "Giao h√†ng nhanh ch√≥ng. H∆°i nh·ªè so v·ªõi t∆∞·ªüng t∆∞·ª£ng c·ªßa m√¨nh. Z z z nh∆∞ng v·ªõi gi√° ti·ªÅn th√¨ ch·∫•p nh·∫≠n ·∫°. N√™n cho 5 sao\n"
     ]
    }
   ],
   "source": [
    "all_indices = np.arange(len(test_df))\n",
    "\n",
    "remaining_indices = list(set(all_indices) - set(closest))\n",
    "\n",
    "# Ch·ªçn ng·∫´u nhi√™n n_hard example t·ª´ ph·∫ßn c√≤n l·∫°i \n",
    "hard_examples = test_df.iloc[remaining_indices].sample(n=n_hard, random_state=42)\n",
    "\n",
    "print(f\"Selected {len(hard_examples)} hard examples:\")\n",
    "for i, row in hard_examples.iterrows():\n",
    "    print(f\"\\nExample {i}:\\n{row['data']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d75fd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51/51 [00:12<00:00,  4.19it/s]\n"
     ]
    }
   ],
   "source": [
    "def select_few_shot_examples(df, text_column, n_total=5, model_name='all-MiniLM-L6-v2', random_state=42):\n",
    "    n_diverse = int(n_total * 0.7)\n",
    "    n_hard = n_total - n_diverse\n",
    "\n",
    "    model = SentenceTransformer(model_name)\n",
    "    embeddings = model.encode(df[text_column].tolist(), show_progress_bar=True)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_diverse, random_state=random_state, n_init=10)\n",
    "    kmeans.fit(embeddings)\n",
    "\n",
    "    closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, embeddings)\n",
    "    diverse_df = df.iloc[closest]\n",
    "\n",
    "    all_indices = np.arange(len(df))\n",
    "    remaining_indices = list(set(all_indices) - set(closest))\n",
    "    hard_df = df.iloc[remaining_indices].sample(n=n_hard, random_state=random_state)\n",
    "\n",
    "    return diverse_df.reset_index(drop=True), hard_df.reset_index(drop=True)\n",
    "\n",
    "# SET-UP FEW-SHOT EXAMPLES\n",
    "diverse, hard = select_few_shot_examples(test_df, text_column='data', n_total=5)\n",
    "\n",
    "few_shot_json =  transform_aspect_sentiment(diverse, 0, 100) + transform_aspect_sentiment(hard, 0, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e3b0cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '0',\n",
       "  'text': 'Son ƒë·∫πp, h√†ng h·ªãnüòÅ, m√™ l·∫Øm lu√¥n, tuy k l·ª≥ nh∆∞ng b√π l·∫°i b√¥i l√™n m√¥i n√≥ kh√¥ng b·ªã kh√¥ m√¥i, xinh l·∫Øm lu√¥n, ƒë√≥ng g√≥i r·∫•t ch·∫Øc ch·∫Øn, gi√° r·∫ª, giao h√†ng t·ª´ TQ v·ªÅ VN n√™n h∆°i l√¢u...nh∆∞ng kh√¥ng saoüòäxinh l√† th√≠chüòÇüòÇ n√™n mua ·ªßng h·ªô shop nh√© m.n',\n",
       "  'sentiments': [{'aspect': 'stayingpower', 'sentiment': 'negative'},\n",
       "   {'aspect': 'texture', 'sentiment': 'positive'},\n",
       "   {'aspect': 'price', 'sentiment': 'positive'},\n",
       "   {'aspect': 'shipping', 'sentiment': 'negative'},\n",
       "   {'aspect': 'packing', 'sentiment': 'positive'}]},\n",
       " {'id': '1',\n",
       "  'text': 'M√†u son ƒë·∫πp nh∆∞ng h∆°i l√¢u kh√¥ t√≠... \\nCh·∫•t son c≈©ng t·∫°m ƒë∆∞·ª£c\\nV·ªè son ƒë·∫πp\\nSon th∆°m c·ª±c luoonnnn',\n",
       "  'sentiments': [{'aspect': 'texture', 'sentiment': 'positive'},\n",
       "   {'aspect': 'smell', 'sentiment': 'positive'},\n",
       "   {'aspect': 'colour', 'sentiment': 'positive'}]},\n",
       " {'id': '2',\n",
       "  'text': 'ƒë·∫πppppppppppp xƒ©uuuuuuuuuuuu hdjhsjsjsjdjdjjdjdjdjdjd',\n",
       "  'sentiments': [{'aspect': 'others', 'sentiment': 'neutral'}]},\n",
       " {'id': '0',\n",
       "  'text': 'son s·ªãn . m√†u ƒë·∫πp jaisidiisisjsjsjsjdiididdiidjsjdjjdididi',\n",
       "  'sentiments': [{'aspect': 'colour', 'sentiment': 'positive'}]},\n",
       " {'id': '1',\n",
       "  'text': 'Giao h√†ng nhanh ch√≥ng. H∆°i nh·ªè so v·ªõi t∆∞·ªüng t∆∞·ª£ng c·ªßa m√¨nh. Z z z nh∆∞ng v·ªõi gi√° ti·ªÅn th√¨ ch·∫•p nh·∫≠n ·∫°. N√™n cho 5 sao',\n",
       "  'sentiments': [{'aspect': 'price', 'sentiment': 'positive'},\n",
       "   {'aspect': 'shipping', 'sentiment': 'positive'}]}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_json[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "907b598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_aspect_sentiment(ground_truth, predictions):\n",
    "    true_aspects = []\n",
    "    pred_aspects = []\n",
    "\n",
    "    true_aspect_sentiments = []\n",
    "    pred_aspect_sentiments = []\n",
    "\n",
    "    for gt_entry, pred_entry in zip(ground_truth, predictions):\n",
    "        gt_sents = gt_entry['sentiments']\n",
    "        gt_aspect_set = set()\n",
    "        gt_aspect_sentiment_set = set()\n",
    "\n",
    "        for item in gt_sents:\n",
    "            gt_aspect_set.add(item['aspect'])\n",
    "            gt_aspect_sentiment_set.add((item['aspect'], item['sentiment']))\n",
    "\n",
    "        true_aspects.append(gt_aspect_set)\n",
    "        true_aspect_sentiments.append(gt_aspect_sentiment_set)\n",
    "\n",
    "        pred_sents = pred_entry['results']\n",
    "        pred_aspect_set = set()\n",
    "        pred_aspect_sentiment_set = set()\n",
    "\n",
    "        for item in pred_sents:\n",
    "            pred_aspect_set.add(item['aspect'])\n",
    "            pred_aspect_sentiment_set.add((item['aspect'], item['sentiment']))\n",
    "\n",
    "        pred_aspects.append(pred_aspect_set)\n",
    "        pred_aspect_sentiments.append(pred_aspect_sentiment_set)\n",
    "\n",
    "    all_true_aspects = set.union(*true_aspects) if true_aspects else set()\n",
    "    all_pred_aspects = set.union(*pred_aspects) if pred_aspects else set()\n",
    "\n",
    "    tp_aspect = sum(len(gt & pred) for gt, pred in zip(true_aspects, pred_aspects))\n",
    "    fp_aspect = sum(len(pred - gt) for gt, pred in zip(true_aspects, pred_aspects))\n",
    "    fn_aspect = sum(len(gt - pred) for gt, pred in zip(true_aspects, pred_aspects))\n",
    "\n",
    "    precision_aspect = tp_aspect / (tp_aspect + fp_aspect + 1e-8)\n",
    "    recall_aspect = tp_aspect / (tp_aspect + fn_aspect + 1e-8)\n",
    "    f1_aspect = 2 * precision_aspect * recall_aspect / (precision_aspect + recall_aspect + 1e-8)\n",
    "\n",
    "    tp_sentiment = sum(len(gt & pred) for gt, pred in zip(true_aspect_sentiments, pred_aspect_sentiments))\n",
    "    fp_sentiment = sum(len(pred - gt) for gt, pred in zip(true_aspect_sentiments, pred_aspect_sentiments))\n",
    "    fn_sentiment = sum(len(gt - pred) for gt, pred in zip(true_aspect_sentiments, pred_aspect_sentiments))\n",
    "\n",
    "    precision_sentiment = tp_sentiment / (tp_sentiment + fp_sentiment + 1e-8)\n",
    "    recall_sentiment = tp_sentiment / (tp_sentiment + fn_sentiment + 1e-8)\n",
    "    f1_sentiment = 2 * precision_sentiment * recall_sentiment / (precision_sentiment + recall_sentiment + 1e-8)\n",
    "\n",
    "    return {\n",
    "        \"Aspect Detection F1\": f1_aspect,\n",
    "        \"Sentiment Classification F1\": f1_sentiment\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6f42fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [03:53<00:00,  2.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# Setup Grok API\n",
    "def call_grok_api(prompt):\n",
    "    url = \"https://api.x.ai/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {os.getenv('GROK_API_KEY')}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": \"grok-3\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts aspects and their sentiments from text.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=data, timeout=30)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result['choices'][0]['message']['content']\n",
    "        else:\n",
    "            print(f\"API Error: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Request Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_clustering_prompt(text, few_shot_examples):\n",
    "    prompt = \"You are an AI assistant that extracts aspects and their sentiments from text.\\n\\n\"\n",
    "    \n",
    "    # Th√™m few-shot examples\n",
    "    for ex in few_shot_examples:\n",
    "        prompt += f\"Extract aspects and sentiments from the following review:\\n{ex['text']}\\n\"\n",
    "        prompt += f\"Result: {json.dumps({'results': ex['sentiments']}, ensure_ascii=False)}\\n\\n\"\n",
    "    \n",
    "    # Th√™m c√¢u h·ªèi hi·ªán t·∫°i\n",
    "    prompt += f\"Extract aspects and sentiments from the following review:\\n{text}\\n\"\n",
    "    prompt += f\"Available aspects: {', '.join(aspects)}\\n\"\n",
    "    prompt += \"Available sentiments: positive, negative, neutral\\n\"\n",
    "    prompt += \"Return ONLY a valid JSON object in this exact format:\\n\"\n",
    "    prompt += '{\"results\": [{\"aspect\": \"aspect_name\", \"sentiment\": \"sentiment_value\"}]}'\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def extract_with_grok_clustering(text, few_shot_examples):\n",
    "    prompt = create_clustering_prompt(text, few_shot_examples)\n",
    "    response_text = call_grok_api(prompt)\n",
    "    \n",
    "    if response_text:\n",
    "        try:\n",
    "            # T√¨m JSON trong response\n",
    "            start_idx = response_text.find('{')\n",
    "            end_idx = response_text.rfind('}') + 1\n",
    "            \n",
    "            if start_idx != -1 and end_idx != -1:\n",
    "                json_str = response_text[start_idx:end_idx]\n",
    "                parsed_output = json.loads(json_str)\n",
    "                return parsed_output\n",
    "            else:\n",
    "                return {\"results\": []}\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"JSON Parse Error: {response_text}\")\n",
    "            return {\"results\": []}\n",
    "    else:\n",
    "        return {\"results\": []}\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# D·ª± ƒëo√°n\n",
    "for data in tqdm(test_json):\n",
    "    prediction = extract_with_grok_clustering(data['text'], few_shot_json)\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e63b573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Aspect Detection F1': 0.9060240913734939, 'Sentiment Classification F1': 0.785542163668457}\n"
     ]
    }
   ],
   "source": [
    "scores = evaluate_aspect_sentiment(test_json, predictions)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5f29b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = path.join(RESULT_DIR, 'ViABSA_BP_Few-shot-BP-Grok.json')\n",
    "with open(result_file, 'w') as f:\n",
    "    json.dump(predictions, f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ABSA_Prompting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
