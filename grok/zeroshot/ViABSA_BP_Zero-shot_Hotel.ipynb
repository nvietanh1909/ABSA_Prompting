{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea9126dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Định nghĩa đường dẫn\n",
    "DATA_DIR = r\"c:\\Users\\Admin\\Python\\ABSA_Prompting\\data\"\n",
    "RESULT_DIR = r\"c:\\Users\\Admin\\Python\\ABSA_Prompting\\results\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6da33faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a9a7637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "ViABSA_BP_dir = path.join(DATA_DIR, 'ViABSA_Hotel')\n",
    "test_file = path.join(ViABSA_BP_dir, 'data_test.csv')\n",
    "test_df = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20757cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects = [\n",
    "    \"FACILITIES#CLEANLINESS\",\n",
    "    \"FACILITIES#COMFORT\",\n",
    "    \"FACILITIES#DESIGN&FEATURES\",\n",
    "    \"FACILITIES#GENERAL\",\n",
    "    \"FACILITIES#MISCELLANEOUS\",\n",
    "    \"FACILITIES#PRICES\",\n",
    "    \"FACILITIES#QUALITY\",\n",
    "    \"FOOD&DRINKS#MISCELLANEOUS\",\n",
    "    \"FOOD&DRINKS#PRICES\",\n",
    "    \"FOOD&DRINKS#QUALITY\",\n",
    "    \"FOOD&DRINKS#STYLE&OPTIONS\",\n",
    "    \"HOTEL#CLEANLINESS\",\n",
    "    \"HOTEL#COMFORT\",\n",
    "    \"HOTEL#DESIGN&FEATURES\",\n",
    "    \"HOTEL#GENERAL\",\n",
    "    \"HOTEL#MISCELLANEOUS\",\n",
    "    \"HOTEL#PRICES\",\n",
    "    \"HOTEL#QUALITY\",\n",
    "    \"LOCATION#GENERAL\",\n",
    "    \"ROOMS#CLEANLINESS\",\n",
    "    \"ROOMS#COMFORT\",\n",
    "    \"ROOMS#DESIGN&FEATURES\",\n",
    "    \"ROOMS#GENERAL\",\n",
    "    \"ROOMS#MISCELLANEOUS\",\n",
    "    \"ROOMS#PRICES\",\n",
    "    \"ROOMS#QUALITY\",\n",
    "    \"ROOM_AMENITIES#CLEANLINESS\",\n",
    "    \"ROOM_AMENITIES#COMFORT\",\n",
    "    \"ROOM_AMENITIES#DESIGN&FEATURES\",\n",
    "    \"ROOM_AMENITIES#GENERAL\",\n",
    "    \"ROOM_AMENITIES#MISCELLANEOUS\",\n",
    "    \"ROOM_AMENITIES#PRICES\",\n",
    "    \"ROOM_AMENITIES#QUALITY\",\n",
    "    \"SERVICE#GENERAL\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6475dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = {\n",
    "    1: \"positive\",\n",
    "    2: \"negative\",\n",
    "    3: \"neutral\"\n",
    "}\n",
    "\n",
    "def transform_aspect_sentiment(df, start=0, end=None):\n",
    "    result = [] \n",
    "    \n",
    "    if end is None:\n",
    "        end = len(df)\n",
    "\n",
    "    for idx, row in df.iloc[start:end].iterrows():\n",
    "        entry = {\n",
    "            \"id\": str(idx),\n",
    "            \"text\": row['Review'],\n",
    "            \"sentiments\": []\n",
    "        }\n",
    "\n",
    "        for aspect in aspects:\n",
    "            sentiment = row[f\"{aspect}_label\"]\n",
    "            if sentiment == 1:  # chỉ lấy những cái có sentiment\n",
    "                aspect_sentiment_value = row[aspect]\n",
    "                mapped_sent = sentiment_map.get(aspect_sentiment_value, \"unknown\")\n",
    "                if aspect_sentiment_value != 'none':\n",
    "                    entry[\"sentiments\"].append({\n",
    "                        \"aspect\": aspect,\n",
    "                        \"sentiment\": mapped_sent\n",
    "                    })\n",
    "                else:\n",
    "                    # nếu cột sentiment text bị none nhưng label == 1 thì có thể log ra kiểm tra\n",
    "                    entry[\"sentiments\"].append({\n",
    "                        \"aspect\": aspect,\n",
    "                        \"sentiment\": \"unknown\"\n",
    "                    })\n",
    "\n",
    "        result.append(entry)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc6f184d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '0',\n",
       "  'text': 'Ga giường không sạch, nhân viên quên dọn phòng một ngày.',\n",
       "  'sentiments': [{'aspect': 'ROOM_AMENITIES#CLEANLINESS',\n",
       "    'sentiment': 'negative'},\n",
       "   {'aspect': 'SERVICE#GENERAL', 'sentiment': 'negative'}]},\n",
       " {'id': '1',\n",
       "  'text': 'Nv nhiệt tình, phòng ở sạch sẽ, tiện nghi, vị trí khá thuận tiện cho việc di chuyển đến các địa điểm ăn + chơi Phòng có gián',\n",
       "  'sentiments': [{'aspect': 'LOCATION#GENERAL', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOMS#CLEANLINESS', 'sentiment': 'neutral'},\n",
       "   {'aspect': 'ROOMS#COMFORT', 'sentiment': 'positive'},\n",
       "   {'aspect': 'SERVICE#GENERAL', 'sentiment': 'positive'}]},\n",
       " {'id': '2',\n",
       "  'text': 'Đi bộ ra biển gần, tiện đi lại Phòng view biển nhưng cửa sổ view biển khá bé',\n",
       "  'sentiments': [{'aspect': 'LOCATION#GENERAL', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOMS#DESIGN&FEATURES', 'sentiment': 'neutral'},\n",
       "   {'aspect': 'ROOMS#GENERAL', 'sentiment': 'positive'}]},\n",
       " {'id': '3',\n",
       "  'text': 'Tất cả mọi thứ đều sạch sẽ, giường ngủ rất thoải mái. Không có quạt điện mà chỉ có điều hòa nên có chút bất tiện.',\n",
       "  'sentiments': [{'aspect': 'HOTEL#CLEANLINESS', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOM_AMENITIES#COMFORT', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOM_AMENITIES#DESIGN&FEATURES', 'sentiment': 'negative'}]},\n",
       " {'id': '4',\n",
       "  'text': 'Giường sạch sẽ, thoải mái, đầy đủ thiết bị cần thiết, ăn cũng trang bị sẵn nếu bạn lười Phòng tắm chưa chia được ko gian khô và ướt',\n",
       "  'sentiments': [{'aspect': 'FOOD&DRINKS#STYLE&OPTIONS',\n",
       "    'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOM_AMENITIES#CLEANLINESS', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOM_AMENITIES#COMFORT', 'sentiment': 'positive'},\n",
       "   {'aspect': 'ROOM_AMENITIES#DESIGN&FEATURES', 'sentiment': 'negative'},\n",
       "   {'aspect': 'ROOM_AMENITIES#GENERAL', 'sentiment': 'positive'}]}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SETUP DATA\n",
    "test_df[aspects] = test_df[aspects].fillna('none')\n",
    "\n",
    "for aspect in aspects:\n",
    "    test_df[aspect + '_label'] = (test_df[aspect] != 0).astype(int)\n",
    "\n",
    "test_json = transform_aspect_sentiment(test_df, 0, 100)\n",
    "test_json[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f843ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_aspect_sentiment(ground_truth, predictions):\n",
    "    # Chuẩn hóa dữ liệu thành list các tuple để so sánh\n",
    "    true_aspects = []\n",
    "    pred_aspects = []\n",
    "\n",
    "    true_aspect_sentiments = []\n",
    "    pred_aspect_sentiments = []\n",
    "\n",
    "    for gt_entry, pred_entry in zip(ground_truth, predictions):\n",
    "        # ground truth: list of sentiments\n",
    "        gt_sents = gt_entry['sentiments']\n",
    "        gt_aspect_set = set()\n",
    "        gt_aspect_sentiment_set = set()\n",
    "\n",
    "        for item in gt_sents:\n",
    "            gt_aspect_set.add(item['aspect'])\n",
    "            gt_aspect_sentiment_set.add((item['aspect'], item['sentiment']))\n",
    "\n",
    "        true_aspects.append(gt_aspect_set)\n",
    "        true_aspect_sentiments.append(gt_aspect_sentiment_set)\n",
    "\n",
    "        # prediction: list of results\n",
    "        pred_sents = pred_entry['results']\n",
    "        pred_aspect_set = set()\n",
    "        pred_aspect_sentiment_set = set()\n",
    "\n",
    "        for item in pred_sents:\n",
    "            pred_aspect_set.add(item['aspect'])\n",
    "            pred_aspect_sentiment_set.add((item['aspect'], item['sentiment']))\n",
    "\n",
    "        pred_aspects.append(pred_aspect_set)\n",
    "        pred_aspect_sentiments.append(pred_aspect_sentiment_set)\n",
    "\n",
    "    # Tính theo micro-F1 (gộp hết lại)\n",
    "    all_true_aspects = set.union(*true_aspects) if true_aspects else set()\n",
    "    all_pred_aspects = set.union(*pred_aspects) if pred_aspects else set()\n",
    "\n",
    "    tp_aspect = sum(len(gt & pred) for gt, pred in zip(true_aspects, pred_aspects))\n",
    "    fp_aspect = sum(len(pred - gt) for gt, pred in zip(true_aspects, pred_aspects))\n",
    "    fn_aspect = sum(len(gt - pred) for gt, pred in zip(true_aspects, pred_aspects))\n",
    "\n",
    "    precision_aspect = tp_aspect / (tp_aspect + fp_aspect + 1e-8)\n",
    "    recall_aspect = tp_aspect / (tp_aspect + fn_aspect + 1e-8)\n",
    "    f1_aspect = 2 * precision_aspect * recall_aspect / (precision_aspect + recall_aspect + 1e-8)\n",
    "\n",
    "    # Tính cho sentiment classification\n",
    "    tp_sentiment = sum(len(gt & pred) for gt, pred in zip(true_aspect_sentiments, pred_aspect_sentiments))\n",
    "    fp_sentiment = sum(len(pred - gt) for gt, pred in zip(true_aspect_sentiments, pred_aspect_sentiments))\n",
    "    fn_sentiment = sum(len(gt - pred) for gt, pred in zip(true_aspect_sentiments, pred_aspect_sentiments))\n",
    "\n",
    "    precision_sentiment = tp_sentiment / (tp_sentiment + fp_sentiment + 1e-8)\n",
    "    recall_sentiment = tp_sentiment / (tp_sentiment + fn_sentiment + 1e-8)\n",
    "    f1_sentiment = 2 * precision_sentiment * recall_sentiment / (precision_sentiment + recall_sentiment + 1e-8)\n",
    "\n",
    "    return {\n",
    "        \"Aspect Detection F1\": f1_aspect,\n",
    "        \"Sentiment Classification F1\": f1_sentiment\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3b2fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_functions = [\n",
    "    {\n",
    "        \"name\": \"extract_aspect_sentiment\",\n",
    "        \"description\": \"Extract aspects and sentiments from text, Think step by step exactly\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"results\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"aspect\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"enum\": aspects\n",
    "                            },\n",
    "                            \"sentiment\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"enum\": [\"positive\", \"negative\", \"neutral\"]\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"aspect\", \"sentiment\"]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"results\"]\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2d5beb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [01:21<05:38,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Parse Error: {\" there! I'm happy to help with extracting aspects and sentiments from the provided review. Based on the text, I've identified the relevant aspects and their corresponding sentiments. Here's the result in the requested JSON format:\n",
      "\n",
      "{\"results\": [\n",
      "    {\"aspect\": \"LOCATION#GENERAL\", \"sentiment\": \"positive\"},\n",
      "    {\"aspect\": \"ROOMS#GENERAL\", \"sentiment\": \"positive\"},\n",
      "    {\"aspect\": \"ROOM_AMENITIES#GENERAL\", \"sentiment\": \"positive\"},\n",
      "    {\"aspect\": \"SERVICE#GENERAL\", \"sentiment\": \"positive\"}\n",
      "]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [03:38<03:00,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Parse Error: {\n",
      " there! I'm happy to help with extracting aspects and sentiments from the review. Here's the result in the requested JSON format:\n",
      "\n",
      "{\"results\": [\n",
      "    {\"aspect\": \"ROOMS#CLEANLINESS\", \"sentiment\": \"positive\"},\n",
      "    {\"aspect\": \"ROOMS#DESIGN&FEATURES\", \"sentiment\": \"positive\"},\n",
      "    {\"aspect\": \"SERVICE#GENERAL\", \"sentiment\": \"positive\"},\n",
      "    {\"aspect\": \"HOTEL#GENERAL\", \"sentiment\": \"positive\"}\n",
      "]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:07<00:00,  3.67s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Setup Grok API\n",
    "def call_grok_api(prompt):\n",
    "    url = \"https://api.x.ai/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {os.getenv('GROK_API_KEY')}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": \"grok-3\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts aspects and their sentiments from text.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=data, timeout=30)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result['choices'][0]['message']['content']\n",
    "        else:\n",
    "            print(f\"API Error: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Request Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_with_grok(text):\n",
    "    \"\"\"\n",
    "    Trích xuất aspect và sentiment sử dụng Grok API\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Extract aspects and sentiments from the following review:\n",
    "    {text}\n",
    "    \n",
    "    Available aspects: {', '.join(aspects)}\n",
    "    Available sentiments: positive, negative, neutral\n",
    "    \n",
    "    Return ONLY a valid JSON object in this exact format:\n",
    "    {{\"results\": [{{\"aspect\": \"aspect_name\", \"sentiment\": \"sentiment_value\"}}]}}\n",
    "    \"\"\"\n",
    "    \n",
    "    response_text = call_grok_api(prompt)\n",
    "    \n",
    "    if response_text:\n",
    "        try:\n",
    "            # Tìm JSON trong response\n",
    "            start_idx = response_text.find('{')\n",
    "            end_idx = response_text.rfind('}') + 1\n",
    "            \n",
    "            if start_idx != -1 and end_idx != -1:\n",
    "                json_str = response_text[start_idx:end_idx]\n",
    "                parsed_output = json.loads(json_str)\n",
    "                return parsed_output\n",
    "            else:\n",
    "                return {\"results\": []}\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"JSON Parse Error: {response_text}\")\n",
    "            return {\"results\": []}\n",
    "    else:\n",
    "        return {\"results\": []}\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for data in tqdm(test_json):\n",
    "    prediction = extract_with_grok(data['text'])\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2703215f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Aspect Detection F1': 0.6748166209309786, 'Sentiment Classification F1': 0.6136919265559448}\n"
     ]
    }
   ],
   "source": [
    "scores = evaluate_aspect_sentiment(test_json, predictions)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3e8677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = path.join(RESULT_DIR, 'ViABSA_BP_Zero-shot-Hotel_Grok.json')\n",
    "with open(result_file, 'w') as f:\n",
    "    json.dump(predictions, f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ABSA_Prompting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
