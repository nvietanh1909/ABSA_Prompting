{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Python\\ABSA_Prompting\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\Python\\ABSA_Prompting\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from mint.config import DATA_DIR, RESULT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function dotenv.main.load_dotenv(dotenv_path: Union[str, ForwardRef('os.PathLike[str]'), NoneType] = None, stream: Optional[IO[str]] = None, verbose: bool = False, override: bool = False, interpolate: bool = True, encoding: Optional[str] = 'utf-8') -> bool>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "ViABSA_BP_dir = path.join(DATA_DIR, 'ViABSA_BP')\n",
    "test_file = path.join(ViABSA_BP_dir, 'data_test.csv')\n",
    "test_df = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_aspect_sentiment(df, start=0, end=None):\n",
    "    aspects = [\n",
    "        \"stayingpower\",\n",
    "        \"texture\",\n",
    "        \"smell\",\n",
    "        \"price\",\n",
    "        \"others\",\n",
    "        \"colour\",\n",
    "        \"shipping\",\n",
    "        \"packing\"\n",
    "    ]\n",
    "\n",
    "    if end is None:\n",
    "        end = len(df)\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for idx, row in df.iloc[start:end].iterrows():\n",
    "        entry = {\n",
    "            \"id\": str(idx),\n",
    "            \"text\": row['data'],\n",
    "            \"sentiments\": []\n",
    "        }\n",
    "\n",
    "        for aspect in aspects:\n",
    "            sentiment = row[f\"{aspect}_label\"]\n",
    "            if sentiment == 1: \n",
    "                aspect_sentiment_value = row[aspect]\n",
    "                if aspect_sentiment_value != 'none':\n",
    "                    entry[\"sentiments\"].append({\n",
    "                        \"aspect\": aspect,\n",
    "                        \"sentiment\": aspect_sentiment_value\n",
    "                    })\n",
    "                else:\n",
    "                    entry[\"sentiments\"].append({\n",
    "                        \"aspect\": aspect,\n",
    "                        \"sentiment\": \"unknown\"\n",
    "                    })\n",
    "\n",
    "        result.append(entry)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '0',\n",
       "  'text': 'HÃ ng Ä‘Ã³ng gÃ³i Ä‘áº¹p vÃ  cháº¯c cháº¯n, nhÃ¬n ráº¥t dá»… thÆ°Æ¡ng vÃ  Æ°ng bá»¥ng áº¡!',\n",
       "  'sentiments': [{'aspect': 'packing', 'sentiment': 'positive'}]},\n",
       " {'id': '1',\n",
       "  'text': 'Cáº£m giÃ¡c son bÃªn trong ráº¥t lÃ  Ã­t luÃ´n Ã­, Ä‘Ã³ng gÃ³i cáº©n tháº­n, dá»‹ch nhÆ°ng mÃ  giao hÃ ng khÃ¡ nhanh',\n",
       "  'sentiments': [{'aspect': 'shipping', 'sentiment': 'positive'},\n",
       "   {'aspect': 'packing', 'sentiment': 'positive'}]},\n",
       " {'id': '2',\n",
       "  'text': 'Son siÃªu Ä‘áº¹p luÃ´n Ã½, mÃ  y hÃ¬nh mÃ  chá»¥p cÃ³ thá»ƒ khÃ´ng giá»‘ng láº¯m nhÆ°ng nhÃ¬n ngoÃ i thÃ¬ giá»‘ng nha. Cháº¥t son má»m mÆ°á»›t nÃ³i chung lÃ  ráº¥t thÃ­chhhh',\n",
       "  'sentiments': [{'aspect': 'texture', 'sentiment': 'positive'}]},\n",
       " {'id': '3',\n",
       "  'text': 'Siu Ä‘áº¹p luÃ´n \\r\\nShop Ä‘Ã³ng gÃ³i cáº©n tháº­n láº¯m luÃ´n \\r\\nLáº¡i thÃªm cáº£ quÃ  ná»¯a\\r\\nNÃ³i chung lÃ  thÃ­ch láº¯m',\n",
       "  'sentiments': [{'aspect': 'packing', 'sentiment': 'positive'}]},\n",
       " {'id': '4',\n",
       "  'text': 'AÃºhihÄ‘cyihb gfxxth jj bhgfzÄ‘E G GHVHBTCEETXUBBIYCZRZRTCVUUBYRZXGVBIINVUTXZRCTIBONONBUXTZRTVKNNOUVTXEecyuvknibtcrztxuvbubibijvcytdgunonobiyvdtrdfyyghuojpmibvytcdtvunomobuCYYVBIBIYCTXYVIONNIXTXTBUOJMOONBIYCXRTXVYBUINNONIBUCTTXTCYVIBONON',\n",
       "  'sentiments': [{'aspect': 'others', 'sentiment': 'neutral'}]}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SETUP DATA\n",
    "aspects = ['stayingpower', 'texture', 'smell', 'price', 'others', 'colour', 'shipping', 'packing']\n",
    "test_df[aspects] = test_df[aspects].fillna('none')\n",
    "\n",
    "for aspect in aspects:\n",
    "    test_df[aspect + '_label'] = (test_df[aspect] != 'none').astype(int)\n",
    "\n",
    "test_json = transform_aspect_sentiment(test_df, 0, 100)\n",
    "test_json[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ã tÆ°á»Ÿng chá»n example cho few-shot**\n",
    "1.   Chá»n ra top-k vá»›i vÃ­ dá»¥ gáº§n nháº¥t vá»›i input hiá»‡n táº¡i\n",
    "2.   Táº¡o prompt khÃ¡c nhau cho tá»«ng input\n",
    "\n",
    "Ãp dá»¥ng retrieval-based dynamic few-shot prompting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_examples(candidate_examples, review_to_predict, k=3, model_name='all-MiniLM-L6-v2'):\n",
    "    # Lá»c láº¡i Ä‘á»ƒ khÃ´ng trÃ¹ng text vá»›i input\n",
    "    filtered_candidates = [ex for ex in candidate_examples if ex[\"text\"].strip() != review_to_predict.strip()]\n",
    "\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    example_texts = [ex['text'] for ex in filtered_candidates]\n",
    "    all_texts = example_texts + [review_to_predict]\n",
    "    embeddings = model.encode(all_texts)\n",
    "\n",
    "    # láº¥y vector cuá»‘i\n",
    "    review_emb = embeddings[-1].reshape(1, -1)\n",
    "    # láº¥y táº¥t cáº£ trá»« vector cuá»‘i\n",
    "    example_embs = embeddings[:-1]\n",
    "    \n",
    "    # tÃ­nh cosine similarity\n",
    "    sims = cosine_similarity(review_emb, example_embs)[0]\n",
    "    top_k_idx = np.argsort(sims)[-k:][::-1]\n",
    "\n",
    "    return [candidate_examples[i] for i in top_k_idx]\n",
    "\n",
    "\n",
    "def build_dynamic_prompt(review_to_predict, top_examples):\n",
    "    prompt = 'Extract aspects and sentiments from the following review:.\\n\\n'\n",
    "    prompt += f'Data: {review_to_predict}\\n'\n",
    "    prompt += 'Examples:\\n'\n",
    "    for ex in top_examples:\n",
    "        if ex[\"text\"].strip() != review_to_predict.strip():  # Bá» vÃ­ dá»¥ trÃ¹ng\n",
    "            prompt += f'Review: \"{ex[\"text\"]}\"\\nOutput: {json.dumps(ex[\"sentiments\"], ensure_ascii=False)}\\n\\n'\n",
    "    prompt += f'Review: \"{review_to_predict}\"\\nOutput:'\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '27',\n",
       "  'text': 'ÄÃ³ng gÃ³i ok, 02 mÃ¹i khÃ¡ thÆ¡m, son ko Ä‘c Ä‘áº§y cho láº¯m, vs giÃ¡ Ä‘Ã³ thÃ¬ ko mong nhiá»u',\n",
       "  'sentiments': [{'aspect': 'smell', 'sentiment': 'positive'},\n",
       "   {'aspect': 'price', 'sentiment': 'positive'},\n",
       "   {'aspect': 'packing', 'sentiment': 'positive'}]},\n",
       " {'id': '81',\n",
       "  'text': 'Hehee áº£nh cá»§a chÃ¬ káº» máº¯t nma son xá»‹n ghÃª lun mng mÃ u xinh Ã¡ ğŸ¶ğŸ¶ğŸ¶ğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆ',\n",
       "  'sentiments': [{'aspect': 'colour', 'sentiment': 'positive'}]},\n",
       " {'id': '42',\n",
       "  'text': 'HÃ¬nh áº£nh mang tÃ­nh cháº¥t minh hoáº¡ ğŸŒ¸ğŸŒ¸ğŸ’•ğŸŒ¸ğŸ’•ğŸŒ¸ğŸ’•ğŸŒ¸ğŸ’•ğŸŒ¸ğŸ’•ğŸ˜³ğŸ’•ğŸŒ¸ğŸ’•ğŸŒ¸ğŸŒ¸ğŸ’•ğŸŒ¸ğŸŒ¸ğŸ’•ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸',\n",
       "  'sentiments': [{'aspect': 'others', 'sentiment': 'neutral'}]},\n",
       " {'id': '72',\n",
       "  'text': 'ráº¥t ok\\n\\n\\nuuhshduddhd',\n",
       "  'sentiments': [{'aspect': 'others', 'sentiment': 'neutral'}]},\n",
       " {'id': '38',\n",
       "  'text': 'Giao hÃ ng nhanh láº¯m áº¡. Chá»‰ mong cÃ¡c shop nÆ°á»›c ngoÃ i cÅ©ng nhanh nhÆ° shop nÃ y thÃ´i. Æ¯ng tháº­t sá»±',\n",
       "  'sentiments': [{'aspect': 'shipping', 'sentiment': 'positive'}]}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_examples = get_top_k_examples(test_json, \"HÃ ng Ä‘Ã³ng gÃ³i Ä‘áº¹p vÃ  cháº¯c cháº¯n, nhÃ¬n ráº¥t dá»… thÆ°Æ¡ng vÃ  Æ°ng bá»¥ng áº¡!\", k=5, model_name='all-MiniLM-L6-v2')\n",
    "top_examples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract aspects and sentiments from the following review:.\n",
      "\n",
      "Data: HÃ ng Ä‘Ã³ng gÃ³i Ä‘áº¹p vÃ  cháº¯c cháº¯n, nhÃ¬n ráº¥t dá»… thÆ°Æ¡ng vÃ  Æ°ng bá»¥ng áº¡!\n",
      "Examples:\n",
      "Review: \"ÄÃ³ng gÃ³i ok, 02 mÃ¹i khÃ¡ thÆ¡m, son ko Ä‘c Ä‘áº§y cho láº¯m, vs giÃ¡ Ä‘Ã³ thÃ¬ ko mong nhiá»u\"\n",
      "Output: [{\"aspect\": \"smell\", \"sentiment\": \"positive\"}, {\"aspect\": \"price\", \"sentiment\": \"positive\"}, {\"aspect\": \"packing\", \"sentiment\": \"positive\"}]\n",
      "\n",
      "Review: \"Hehee áº£nh cá»§a chÃ¬ káº» máº¯t nma son xá»‹n ghÃª lun mng mÃ u xinh Ã¡ ğŸ¶ğŸ¶ğŸ¶ğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆ\"\n",
      "Output: [{\"aspect\": \"colour\", \"sentiment\": \"positive\"}]\n",
      "\n",
      "Review: \"HÃ¬nh áº£nh mang tÃ­nh cháº¥t minh hoáº¡ ğŸŒ¸ğŸŒ¸ğŸ’•ğŸŒ¸ğŸ’•ğŸŒ¸ğŸ’•ğŸŒ¸ğŸ’•ğŸŒ¸ğŸ’•ğŸ˜³ğŸ’•ğŸŒ¸ğŸ’•ğŸŒ¸ğŸŒ¸ğŸ’•ğŸŒ¸ğŸŒ¸ğŸ’•ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸\"\n",
      "Output: [{\"aspect\": \"others\", \"sentiment\": \"neutral\"}]\n",
      "\n",
      "Review: \"ráº¥t ok\n",
      "\n",
      "\n",
      "uuhshduddhd\"\n",
      "Output: [{\"aspect\": \"others\", \"sentiment\": \"neutral\"}]\n",
      "\n",
      "Review: \"Giao hÃ ng nhanh láº¯m áº¡. Chá»‰ mong cÃ¡c shop nÆ°á»›c ngoÃ i cÅ©ng nhanh nhÆ° shop nÃ y thÃ´i. Æ¯ng tháº­t sá»±\"\n",
      "Output: [{\"aspect\": \"shipping\", \"sentiment\": \"positive\"}]\n",
      "\n",
      "Review: \"HÃ ng Ä‘Ã³ng gÃ³i Ä‘áº¹p vÃ  cháº¯c cháº¯n, nhÃ¬n ráº¥t dá»… thÆ°Æ¡ng vÃ  Æ°ng bá»¥ng áº¡!\"\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "prompt = build_dynamic_prompt(\"HÃ ng Ä‘Ã³ng gÃ³i Ä‘áº¹p vÃ  cháº¯c cháº¯n, nhÃ¬n ráº¥t dá»… thÆ°Æ¡ng vÃ  Æ°ng bá»¥ng áº¡!\", top_examples)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_functions = [\n",
    "    {\n",
    "        \"name\": \"extract_aspect_sentiment\",\n",
    "        \"description\": \"Extract aspects and sentiments from text\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"results\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"aspect\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"enum\": aspects\n",
    "                            },\n",
    "                            \"sentiment\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"enum\": [\"positive\", \"negative\", \"neutral\"]\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"aspect\", \"sentiment\"]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"results\"]\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_aspect_sentiment(ground_truth, predictions):\n",
    "    true_aspects = []\n",
    "    pred_aspects = []\n",
    "\n",
    "    true_aspect_sentiments = []\n",
    "    pred_aspect_sentiments = []\n",
    "\n",
    "    for gt_entry, pred_entry in zip(ground_truth, predictions):\n",
    "        gt_sents = gt_entry['sentiments']\n",
    "        gt_aspect_set = set()\n",
    "        gt_aspect_sentiment_set = set()\n",
    "\n",
    "        for item in gt_sents:\n",
    "            gt_aspect_set.add(item['aspect'])\n",
    "            gt_aspect_sentiment_set.add((item['aspect'], item['sentiment']))\n",
    "\n",
    "        true_aspects.append(gt_aspect_set)\n",
    "        true_aspect_sentiments.append(gt_aspect_sentiment_set)\n",
    "\n",
    "        pred_sents = pred_entry['results']\n",
    "        pred_aspect_set = set()\n",
    "        pred_aspect_sentiment_set = set()\n",
    "\n",
    "        for item in pred_sents:\n",
    "            pred_aspect_set.add(item['aspect'])\n",
    "            pred_aspect_sentiment_set.add((item['aspect'], item['sentiment']))\n",
    "\n",
    "        pred_aspects.append(pred_aspect_set)\n",
    "        pred_aspect_sentiments.append(pred_aspect_sentiment_set)\n",
    "\n",
    "    all_true_aspects = set.union(*true_aspects) if true_aspects else set()\n",
    "    all_pred_aspects = set.union(*pred_aspects) if pred_aspects else set()\n",
    "\n",
    "    tp_aspect = sum(len(gt & pred) for gt, pred in zip(true_aspects, pred_aspects))\n",
    "    fp_aspect = sum(len(pred - gt) for gt, pred in zip(true_aspects, pred_aspects))\n",
    "    fn_aspect = sum(len(gt - pred) for gt, pred in zip(true_aspects, pred_aspects))\n",
    "\n",
    "    precision_aspect = tp_aspect / (tp_aspect + fp_aspect + 1e-8)\n",
    "    recall_aspect = tp_aspect / (tp_aspect + fn_aspect + 1e-8)\n",
    "    f1_aspect = 2 * precision_aspect * recall_aspect / (precision_aspect + recall_aspect + 1e-8)\n",
    "\n",
    "    tp_sentiment = sum(len(gt & pred) for gt, pred in zip(true_aspect_sentiments, pred_aspect_sentiments))\n",
    "    fp_sentiment = sum(len(pred - gt) for gt, pred in zip(true_aspect_sentiments, pred_aspect_sentiments))\n",
    "    fn_sentiment = sum(len(gt - pred) for gt, pred in zip(true_aspect_sentiments, pred_aspect_sentiments))\n",
    "\n",
    "    precision_sentiment = tp_sentiment / (tp_sentiment + fp_sentiment + 1e-8)\n",
    "    recall_sentiment = tp_sentiment / (tp_sentiment + fn_sentiment + 1e-8)\n",
    "    f1_sentiment = 2 * precision_sentiment * recall_sentiment / (precision_sentiment + recall_sentiment + 1e-8)\n",
    "\n",
    "    return {\n",
    "        \"Aspect Detection F1\": f1_aspect,\n",
    "        \"Sentiment Classification F1\": f1_sentiment\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [08:18<00:00,  4.98s/it]\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "predictions = []\n",
    "\n",
    "for data in tqdm(test_json):\n",
    "    review = data['text']\n",
    "\n",
    "    top_examples = get_top_k_examples(test_json, review, k=5, model_name='all-MiniLM-L6-v2')\n",
    "    prompt = build_dynamic_prompt(review, top_examples)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts aspects and their sentiments from text.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        functions=gpt_functions,\n",
    "        function_call={\"name\": \"extract_aspect_sentiment\"},\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    # Parse káº¿t quáº£\n",
    "    output = response.choices[0].message.function_call.arguments\n",
    "    parsed_output = json.loads(output)\n",
    "    predictions.append(parsed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Aspect Detection F1': 0.8883495095464936, 'Sentiment Classification F1': 0.7632850191475881}\n"
     ]
    }
   ],
   "source": [
    "scores = evaluate_aspect_sentiment(test_json, predictions)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = path.join(RESULT_DIR, 'ViABSA_BP_Few-shot-Similarity.json')\n",
    "with open(result_file, 'w') as f:\n",
    "    json.dump(predictions, f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ABSA_Prompting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
