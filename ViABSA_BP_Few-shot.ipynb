{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from mint.config import DATA_DIR, RESULT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function dotenv.main.load_dotenv(dotenv_path: Union[str, ForwardRef('os.PathLike[str]'), NoneType] = None, stream: Optional[IO[str]] = None, verbose: bool = False, override: bool = False, interpolate: bool = True, encoding: Optional[str] = 'utf-8') -> bool>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "ViABSA_BP_dir = path.join(DATA_DIR, 'ViABSA_BP')\n",
    "test_file = path.join(ViABSA_BP_dir, 'data_test.csv')\n",
    "test_df = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_aspect_sentiment(df, start=0, end=None):\n",
    "    aspects = [\n",
    "        \"stayingpower\",\n",
    "        \"texture\",\n",
    "        \"smell\",\n",
    "        \"price\",\n",
    "        \"others\",\n",
    "        \"colour\",\n",
    "        \"shipping\",\n",
    "        \"packing\"\n",
    "    ]\n",
    "\n",
    "    if end is None:\n",
    "        end = len(df)\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for idx, row in df.iloc[start:end].iterrows():\n",
    "        entry = {\n",
    "            \"id\": str(idx),\n",
    "            \"text\": row['data'],\n",
    "            \"sentiments\": []\n",
    "        }\n",
    "\n",
    "        for aspect in aspects:\n",
    "            sentiment = row[f\"{aspect}_label\"]\n",
    "            if sentiment == 1: \n",
    "                aspect_sentiment_value = row[aspect]\n",
    "                if aspect_sentiment_value != 'none':\n",
    "                    entry[\"sentiments\"].append({\n",
    "                        \"aspect\": aspect,\n",
    "                        \"sentiment\": aspect_sentiment_value\n",
    "                    })\n",
    "                else:\n",
    "                    entry[\"sentiments\"].append({\n",
    "                        \"aspect\": aspect,\n",
    "                        \"sentiment\": \"unknown\"\n",
    "                    })\n",
    "\n",
    "        result.append(entry)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '0',\n",
       "  'text': 'Hàng đóng gói đẹp và chắc chắn, nhìn rất dễ thương và ưng bụng ạ!',\n",
       "  'sentiments': [{'aspect': 'packing', 'sentiment': 'positive'}]},\n",
       " {'id': '1',\n",
       "  'text': 'Cảm giác son bên trong rất là ít luôn í, đóng gói cẩn thận, dịch nhưng mà giao hàng khá nhanh',\n",
       "  'sentiments': [{'aspect': 'shipping', 'sentiment': 'positive'},\n",
       "   {'aspect': 'packing', 'sentiment': 'positive'}]},\n",
       " {'id': '2',\n",
       "  'text': 'Son siêu đẹp luôn ý, mà y hình mà chụp có thể không giống lắm nhưng nhìn ngoài thì giống nha. Chất son mềm mướt nói chung là rất thíchhhh',\n",
       "  'sentiments': [{'aspect': 'texture', 'sentiment': 'positive'}]},\n",
       " {'id': '3',\n",
       "  'text': 'Siu đẹp luôn \\r\\nShop đóng gói cẩn thận lắm luôn \\r\\nLại thêm cả quà nữa\\r\\nNói chung là thích lắm',\n",
       "  'sentiments': [{'aspect': 'packing', 'sentiment': 'positive'}]},\n",
       " {'id': '4',\n",
       "  'text': 'Aúhihđcyihb gfxxth jj bhgfzđE G GHVHBTCEETXUBBIYCZRZRTCVUUBYRZXGVBIINVUTXZRCTIBONONBUXTZRTVKNNOUVTXEecyuvknibtcrztxuvbubibijvcytdgunonobiyvdtrdfyyghuojpmibvytcdtvunomobuCYYVBIBIYCTXYVIONNIXTXTBUOJMOONBIYCXRTXVYBUINNONIBUCTTXTCYVIBONON',\n",
       "  'sentiments': [{'aspect': 'others', 'sentiment': 'neutral'}]}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SETUP DATA\n",
    "aspects = ['stayingpower', 'texture', 'smell', 'price', 'others', 'colour', 'shipping', 'packing']\n",
    "test_df[aspects] = test_df[aspects].fillna('none')\n",
    "\n",
    "for aspect in aspects:\n",
    "    test_df[aspect + '_label'] = (test_df[aspect] != 'none').astype(int)\n",
    "\n",
    "test_json = transform_aspect_sentiment(test_df, 0, 100)\n",
    "test_json[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ý tưởng chọn example cho few-shot**\n",
    "1.   Chọn ra những câu đa dạng về aspect từ dataset -> gôm cụm chúng lại để LLMs hiểu rõ hơn về pattern để học\n",
    "2.   Chọn ra những câu khó, những câu phức tạp hơn \n",
    "\n",
    "Áp dụng K-Means Clustering + Chọn Centroid + Sampling Example khó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 51/51 [00:08<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 7 diverse examples:\n",
      "\n",
      "Example 167:\n",
      "Chất lượng sản phẩm rất tốt, phù hợp với giá tiền, chât son rất đẹp và thơm. Giao hàng nhanh, nên ủng hộ shop lâu dài . Rất thích sản phẩm ở đây\n",
      "\n",
      "Example 213:\n",
      "Nhận đc hàng nhưng giao hàng hơi lâu, mùi son thơm, mướt môi nhưng màu ko giống lắm\n",
      "\n",
      "Example 1591:\n",
      "đẹppppppppppp xĩuuuuuuuuuuuu hdjhsjsjsjdjdjjdjdjdjdjd\n",
      "\n",
      "Example 340:\n",
      "màu lên cũng bth ạ, đẹp. Giao hơi lâu thui ạ, mùi vẫn giống mấy khác ạ\n",
      "\n",
      "Example 1619:\n",
      "Son lên màu đẹp lắm nha,mùi thơm như kẹo socola á. Nói chung giá tiền rẻ nhưng chất lượng theo cảm nhận cá nhân mình thì tuyệt.mỗi tội mình chọn màu hơi tối khum hợp lắm huhu\n",
      "\n",
      "Example 431:\n",
      "shop giao hàng nhanh. Đóng gói cẩn thận. Chưa sử dụng nên chưa biết chất lượng. Sẽ tiếp tục ủng hộ shop\n",
      "\n",
      "Example 1326:\n",
      "Công dụng: son môi\n",
      "Kết cấu: kem\n",
      "Độ bền màu: Tương đối\n",
      "Bôi lên đẹp lắm nhưng k lì lắm nha hhhhhhhh\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Nếu dùng TD-IDF thì sẽ chỉ chọn dựa vào tần suất từ, không hiểu nghĩa của câu -> bị trùng lặp\n",
    "    Semantic grouping để chọn example đa dạng về nội dung, không chỉ về các từ\n",
    "'''\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(test_df['data'].tolist(), show_progress_bar=True)\n",
    "\n",
    "# KMeans clustering (70% đa dạng, 30% khó)\n",
    "n_total = 10\n",
    "n_diverse = int(n_total * 0.7)\n",
    "n_hard = n_total - n_diverse\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_diverse, random_state=42, n_init=10)\n",
    "kmeans.fit(embeddings)\n",
    "\n",
    "# Lấy diverse example gần cluster centroid\n",
    "closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, embeddings)\n",
    "diverse_examples = test_df.iloc[closest]\n",
    "\n",
    "print(f\"Selected {len(diverse_examples)} diverse examples:\")\n",
    "for i, row in diverse_examples.iterrows():\n",
    "    print(f\"\\nExample {i}:\\n{row['data']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 3 hard examples:\n",
      "\n",
      "Example 135:\n",
      "son sịn . màu đẹp jaisidiisisjsjsjsjdiididdiidjsjdjjdididi\n",
      "\n",
      "Example 1432:\n",
      "Shopee mall đóng gói hàng chắc chắn, màu son lên đẹp, dịch nên hàng từ 9/9 bh mới nhận\n",
      "\n",
      "Example 833:\n",
      "Son chất lượng nên mua nha mọi ngừoi rấ đáng giá ạ khá ok ạ nên ok ah\n"
     ]
    }
   ],
   "source": [
    "all_indices = np.arange(len(test_df))\n",
    "\n",
    "remaining_indices = list(set(all_indices) - set(closest))\n",
    "\n",
    "# Chọn ngẫu nhiên n_hard example từ phần còn lại \n",
    "hard_examples = test_df.iloc[remaining_indices].sample(n=n_hard, random_state=42)\n",
    "\n",
    "print(f\"Selected {len(hard_examples)} hard examples:\")\n",
    "for i, row in hard_examples.iterrows():\n",
    "    print(f\"\\nExample {i}:\\n{row['data']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 51/51 [00:08<00:00,  6.32it/s]\n"
     ]
    }
   ],
   "source": [
    "def select_few_shot_examples(df, text_column, n_total=10, model_name='all-MiniLM-L6-v2', random_state=42):\n",
    "    n_diverse = int(n_total * 0.7)\n",
    "    n_hard = n_total - n_diverse\n",
    "\n",
    "    model = SentenceTransformer(model_name)\n",
    "    embeddings = model.encode(df[text_column].tolist(), show_progress_bar=True)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_diverse, random_state=random_state, n_init=10)\n",
    "    kmeans.fit(embeddings)\n",
    "\n",
    "    closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, embeddings)\n",
    "    diverse_df = df.iloc[closest]\n",
    "\n",
    "    all_indices = np.arange(len(df))\n",
    "    remaining_indices = list(set(all_indices) - set(closest))\n",
    "    hard_df = df.iloc[remaining_indices].sample(n=n_hard, random_state=random_state)\n",
    "\n",
    "    return diverse_df.reset_index(drop=True), hard_df.reset_index(drop=True)\n",
    "\n",
    "# SET-UP FEW-SHOT EXAMPLES\n",
    "diverse, hard = select_few_shot_examples(test_df, text_column='data', n_total=5)\n",
    "\n",
    "few_shot_json =  transform_aspect_sentiment(diverse, 0, 100) + transform_aspect_sentiment(hard, 0, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_functions = [\n",
    "    {\n",
    "        \"name\": \"extract_aspect_sentiment\",\n",
    "        \"description\": \"Extract aspects and sentiments from text\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"results\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"aspect\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"enum\": aspects\n",
    "                            },\n",
    "                            \"sentiment\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"enum\": [\"positive\", \"negative\", \"neutral\"]\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"aspect\", \"sentiment\"]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"results\"]\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_aspect_sentiment(ground_truth, predictions):\n",
    "    true_aspects = []\n",
    "    pred_aspects = []\n",
    "\n",
    "    true_aspect_sentiments = []\n",
    "    pred_aspect_sentiments = []\n",
    "\n",
    "    for gt_entry, pred_entry in zip(ground_truth, predictions):\n",
    "        gt_sents = gt_entry['sentiments']\n",
    "        gt_aspect_set = set()\n",
    "        gt_aspect_sentiment_set = set()\n",
    "\n",
    "        for item in gt_sents:\n",
    "            gt_aspect_set.add(item['aspect'])\n",
    "            gt_aspect_sentiment_set.add((item['aspect'], item['sentiment']))\n",
    "\n",
    "        true_aspects.append(gt_aspect_set)\n",
    "        true_aspect_sentiments.append(gt_aspect_sentiment_set)\n",
    "\n",
    "        pred_sents = pred_entry['results']\n",
    "        pred_aspect_set = set()\n",
    "        pred_aspect_sentiment_set = set()\n",
    "\n",
    "        for item in pred_sents:\n",
    "            pred_aspect_set.add(item['aspect'])\n",
    "            pred_aspect_sentiment_set.add((item['aspect'], item['sentiment']))\n",
    "\n",
    "        pred_aspects.append(pred_aspect_set)\n",
    "        pred_aspect_sentiments.append(pred_aspect_sentiment_set)\n",
    "\n",
    "    all_true_aspects = set.union(*true_aspects) if true_aspects else set()\n",
    "    all_pred_aspects = set.union(*pred_aspects) if pred_aspects else set()\n",
    "\n",
    "    tp_aspect = sum(len(gt & pred) for gt, pred in zip(true_aspects, pred_aspects))\n",
    "    fp_aspect = sum(len(pred - gt) for gt, pred in zip(true_aspects, pred_aspects))\n",
    "    fn_aspect = sum(len(gt - pred) for gt, pred in zip(true_aspects, pred_aspects))\n",
    "\n",
    "    precision_aspect = tp_aspect / (tp_aspect + fp_aspect + 1e-8)\n",
    "    recall_aspect = tp_aspect / (tp_aspect + fn_aspect + 1e-8)\n",
    "    f1_aspect = 2 * precision_aspect * recall_aspect / (precision_aspect + recall_aspect + 1e-8)\n",
    "\n",
    "    tp_sentiment = sum(len(gt & pred) for gt, pred in zip(true_aspect_sentiments, pred_aspect_sentiments))\n",
    "    fp_sentiment = sum(len(pred - gt) for gt, pred in zip(true_aspect_sentiments, pred_aspect_sentiments))\n",
    "    fn_sentiment = sum(len(gt - pred) for gt, pred in zip(true_aspect_sentiments, pred_aspect_sentiments))\n",
    "\n",
    "    precision_sentiment = tp_sentiment / (tp_sentiment + fp_sentiment + 1e-8)\n",
    "    recall_sentiment = tp_sentiment / (tp_sentiment + fn_sentiment + 1e-8)\n",
    "    f1_sentiment = 2 * precision_sentiment * recall_sentiment / (precision_sentiment + recall_sentiment + 1e-8)\n",
    "\n",
    "    return {\n",
    "        \"Aspect Detection F1\": f1_aspect,\n",
    "        \"Sentiment Classification F1\": f1_sentiment\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:23<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "predictions = []\n",
    "\n",
    "# Tạo few-shot messages\n",
    "few_shot_messages = []\n",
    "for ex in few_shot_json:\n",
    "    few_shot_messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Extract aspects and sentiments from the following review:\\n{ex['text']}\"\n",
    "    })\n",
    "    few_shot_messages.append({\n",
    "        \"role\": \"function\",\n",
    "        \"name\": \"extract_aspect_sentiment\",\n",
    "        \"content\": json.dumps({\"results\": ex[\"sentiments\"]})\n",
    "    })\n",
    "\n",
    "# Dự đoán\n",
    "for data in tqdm(test_json):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts aspects and their sentiments from text.\"},\n",
    "        *few_shot_messages,\n",
    "        {\"role\": \"user\", \"content\": f\"Extract aspects and sentiments from the following review:\\n{data['text']}\"}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        functions=gpt_functions,\n",
    "        function_call={\"name\": \"extract_aspect_sentiment\"},\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    output = response.choices[0].message.function_call.arguments\n",
    "    parsed_output = json.loads(output)\n",
    "    predictions.append(parsed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Aspect Detection F1': 0.9126213542055096, 'Sentiment Classification F1': 0.7729468548959136}\n"
     ]
    }
   ],
   "source": [
    "scores = evaluate_aspect_sentiment(test_json, predictions)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = path.join(RESULT_DIR, 'ViABSA_BP_Few-shot.json')\n",
    "with open(result_file, 'w') as f:\n",
    "    json.dump(predictions, f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
